{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "transsexual-portrait",
   "metadata": {},
   "source": [
    "# DAX expansion Liquidity - Python\n",
    "\n",
    "### Overview\n",
    "This notebook is the basis of this blog post : https://ganymde.cloud/dax-expansion.html\n",
    "\n",
    "In this sample, we will get an insight on how an index impacts a stock liquidity. We will look back on how DAX index expansion from 30 to 40 stocks impacted liquidity for these new stocks leveraging several APIs we provide.\n",
    "\n",
    "Following the announcement of Deutsche BÃ¶erse in 2020, the index became larger since <i>20 September 2021</i> by incorporating ten of the largest companies from Germany's MDAX listing ðŸ‘‡\n",
    "* *Airbus SE, Brenntag SE, HelloFresh SE, Porsche SE, Puma SE, Qiagen NV, Sartorius AG (Pref. shares), Siemens Healthineers AG, Symrise AG and Zalando SE*\n",
    "\n",
    "In order to understand the **index expansion impact on liquidity** for DAX components, we suggest to request analytical parameters suchs as `traded volumes`, `trades counts`. Each **trade** is pre-mapped, normalized and stored as a *tick trade* in our data store, readily available for on-the-fly analytics.\n",
    "\n",
    "This samples enables to retrieve **on-demand** tick trades data points by calling a dedicated service.\n",
    "\n",
    "### Inputs/outputs\n",
    "Tick trades sample requires instruments' identifiers, date time intervals as per inputs. It returns the tick count sampled using the input time granularity.\n",
    "\n",
    "We will request **tick trades data for the DAX components** before and after the index expansion, on *20 September 2021*. \n",
    "Then, we will compute **liquidity movements** for each new component in order to understand the `integration into index impact on liquidity`.\n",
    "\n",
    "### Services used\n",
    "This sample uses *gRPC requests* in order to retrieve ticks from the dedicated hosted service. The queried endpoint in this script are:\n",
    "* TickTradesService: to directly retrieve tick trades objects from the server.\n",
    "\n",
    "### Modules required\n",
    "1. Systemathics packages:\n",
    "    * *systemathics.apis.services.tick.v1*\n",
    "    * *systemathics.apis.type.shared.v1*\n",
    "    * *google.type*\n",
    "2. Open source packages\n",
    "    * *googleapis-common-protos*\n",
    "    * *protobuf*\n",
    "    * *grpcio*\n",
    "    * *pandas*\n",
    "    * *matpotlib* as per display package\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-glenn",
   "metadata": {},
   "source": [
    "# Run DAX expansion - Liquidity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-negative",
   "metadata": {},
   "source": [
    "### Step 1: Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install googleapis-common-protos protobuf grpcio pandas matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install systemathics.apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import grpc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import google.type.date_pb2 as date\n",
    "import systemathics.apis.type.shared.v1.date_interval_pb2 as dateinterval\n",
    "import systemathics.apis.type.shared.v1.constraints_pb2 as constraints\n",
    "import systemathics.apis.type.shared.v1.identifier_pb2 as identifier\n",
    "import systemathics.apis.services.tick.v1.tick_trades_pb2 as tick_trades\n",
    "import systemathics.apis.services.tick.v1.tick_trades_pb2_grpc as tick_trades_service\n",
    "import systemathics.apis.helpers.token_helpers as token_helpers\n",
    "import systemathics.apis.helpers.channel_helpers as channel_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-dodge",
   "metadata": {},
   "source": [
    "### Step 2: Prepare API requests\n",
    "The following code snippets retrieve authentication token to be used in upcomming API requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token_helpers.get_token()\n",
    "display(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-crown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare request parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-option",
   "metadata": {},
   "source": [
    "#### 3.1 Instruments' selection\n",
    "The following code snippet enables to set the **DAX components**, before and after index expansion. \n",
    "As we are using *ICE data services* as market data source, tickers are simply the `ICE symbols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_components = ['E:ADSD', 'E:ALVD', 'E:BASD', 'E:BAYND', 'E:BEID', 'E:BMWD', 'E:CBKD', 'E:COND', 'E:DAID', 'E:DBKD', 'E:DB1D', 'E:LHAD', 'E:DPWD', 'E:DTED', 'E:EOAND', 'E:FRED', 'E:FMED', 'E:HEID', 'E:HEND', 'E:IFXD', 'E:LIND', 'E:MRKD', 'E:MUV2D', 'E:PSMD', 'E:RWED', 'E:SAPD', 'E:SIED', 'E:TKAD', 'E:VOWD', 'E:VNAD']\n",
    "new_components = ['E:PUMD', 'E:ZALD', 'E:SHLD', 'E:SY1D', 'E:HFGD', 'E:SRTD', 'E:PAH3D', 'E:BNRD', 'E:QIAD', 'E:AIRP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-caribbean",
   "metadata": {},
   "source": [
    "Each ticker is available in a specific ICE data location called `ICE data source` with a **source_Id**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '840' # ICE data location for DAX tickers after source_Id migration  occured on \"date to be added\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-chemistry",
   "metadata": {},
   "source": [
    "#### 3.2 Trades request parameters\n",
    "The following code snippet enables to set the required parameters to call **TickTradesService**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time intervals (we are using Google date format)\n",
    "date_interval = dateinterval.DateInterval(\n",
    "    start_date = date.Date(year = 2021, month = 6, day = 1), \n",
    "    end_date = date.Date(year = 2021, month = 12, day = 2)\n",
    ")\n",
    "\n",
    "# generate constraints based on the previous time selection\n",
    "constraints = constraints.Constraints(\n",
    "    date_intervals = [date_interval]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-senegal",
   "metadata": {},
   "source": [
    "### Step 4: Retrieve data\n",
    "The following code snippet creates a method to handle request creation to **TickTradesService** for a given instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to handle tick trades request creation for each instrument\n",
    "def get_trades_request(instrument_id):\n",
    "    request = tick_trades.TickTradesRequest(\n",
    "        identifiers = [instrument_id],\n",
    "        constraints = constraints\n",
    "    )\n",
    "    return request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-chancellor",
   "metadata": {},
   "source": [
    "The following code snippet creates a method that calls **TickTradesService** and returns an array of two *pandas dataframes*:\n",
    "* 1st dataframe with trade sizes \n",
    "* 2nd dataframe with trades counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to handle tick trades data for a given list of instruments (old/new DAX components)\n",
    "def get_trades_data(tickers):\n",
    "    \n",
    "    df_sizes = pd.DataFrame({'Date': []})\n",
    "    df_sizes = df_sizes.set_index('Date')\n",
    "\n",
    "    df_counts = pd.DataFrame({'Date': []})\n",
    "    df_counts = df_counts.set_index('Date')\n",
    "    \n",
    "    # iterate all instrument identifiers: exhange/ticker pairs\n",
    "    for i in range(len(tickers)):\n",
    "        ticker = tickers[i]\n",
    "        try:\n",
    "            # open a gRPC channel\n",
    "            with channel_helpers.get_grpc_channel() as channel:\n",
    "\n",
    "                # instantiate the tick trades service\n",
    "                instrument_id = identifier.Identifier(exchange = source, ticker = ticker)\n",
    "                request = get_trades_request(instrument_id)\n",
    "                service = tick_trades_service.TickTradesServiceStub(channel)\n",
    "\n",
    "                # process the tick trades request\n",
    "                sizes, counts = {}, {}\n",
    "                for trade in service.TickTrades(request=request, metadata=[('authorization', token)]):\n",
    "                    if trade.trade.price>0:\n",
    "                        date = datetime.fromtimestamp(trade.trade.time_stamp.seconds).date()\n",
    "                        size = trade.trade.size\n",
    "                        if date in sizes:\n",
    "                            sizes[date]+=size\n",
    "                            counts[date] += 1\n",
    "                        else:\n",
    "                            sizes[date] = size\n",
    "                            counts[date] = 1\n",
    "\n",
    "                tmp_df_sizes = pd.DataFrame(data ={'Date': sizes.keys(), f'{ticker}': sizes.values()})\n",
    "                tmp_df_sizes = tmp_df_sizes.set_index('Date')\n",
    "                if (df_sizes.size == 0):\n",
    "                    df_sizes = tmp_df_sizes\n",
    "                else:\n",
    "                    df_sizes = pd.merge(df_sizes, tmp_df_sizes, on=\"Date\")\n",
    "\n",
    "                tmp_df_counts = pd.DataFrame(data ={'Date': counts.keys(), f'{ticker}': counts.values()})\n",
    "                tmp_df_counts = tmp_df_counts.set_index('Date')\n",
    "                if (df_counts.size == 0):\n",
    "                    df_counts = tmp_df_counts\n",
    "                else:\n",
    "                    df_counts = pd.merge(df_counts, tmp_df_counts, on=\"Date\")\n",
    "        except grpc.RpcError as e:\n",
    "            display(e.code().name)\n",
    "            display(e.details())\n",
    "\n",
    "    return [df_sizes, df_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-dutch",
   "metadata": {},
   "source": [
    "#### 4.1 Retrive trades data for DAX previous composition\n",
    "The following code snippet calls the previous method in order to retrieve **daily trade sizes** and **daily trades counts** for `DAX30, previous composition`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array to store 2 dataframes (trade sizes & trades counts) for DAX previous composition, total of 30 tickers\n",
    "#old_trades_data = get_trades_data(old_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access first array element: daily traded sizes for DAX previous composition\n",
    "#old_trades_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access second array element: daily trades counts for DAX previous composition\n",
    "#old_trades_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-jumping",
   "metadata": {},
   "source": [
    "#### 4.2 Retrive trades data for DAX new components\n",
    "The following code snippet calls the previous method in order to retrieve **daily traded sizes** and **daily trades counts** for `DAX new components`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array to store 2 dataframes (traded sizes & trades counts) for DAX new components, total of 10 tickers\n",
    "new_trades_data = get_trades_data(new_components)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "unlimited-selling",
   "metadata": {},
   "source": [
    "#  dataframe containing daily trade counts\n",
    "new_trades_data[0].plot(figsize=(40, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access first array element: daily traded sizes for DAX new components\n",
    "new_sizes = new_trades_data[0]\n",
    "new_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access second array element: daily trades counts for DAX new components\n",
    "new_trades = new_trades_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trades"
   ]
  },
  {
   "cell_type": "raw",
   "id": "biological-brass",
   "metadata": {},
   "source": [
    "new_trades['E:SRTD'].plot(figsize=(40,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-lighting",
   "metadata": {},
   "source": [
    "### Step 5: Liquidity analysis following DAX extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Puma SE', 'Zalando SE', 'Siemens Healthineers AG', 'Symrise AG', 'HelloFresh SE', 'Sartorius AG', ' Porsche Automobil Holding SE', 'Brenntag SE', 'QIAGEN NV', 'Airbus SE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start from June 1st until December 2nd , including September 20th, DAX expansion date\n",
    "start_date = datetime(2021, 6, 1).date()\n",
    "end_date = datetime(2021, 12, 2).date()\n",
    "change_date = datetime(2021, 9, 20).date()\n",
    "day_before_change = datetime(2021, 9, 19).date()\n",
    "\n",
    "# compute traded sizes percentage change\n",
    "size_ratios = (new_sizes[change_date:end_date].mean() - new_sizes[start_date:day_before_change].mean()) / new_sizes[start_date:day_before_change].mean()\n",
    "liquidity_size_ratios = round(size_ratios*100, 2)\n",
    "liquidity_size_changes = pd.DataFrame({'Name': names,'Ticker': liquidity_size_ratios.index, 'Traded size movement (%)': liquidity_size_ratios.values})\n",
    "\n",
    "# compute trade count percentage change \n",
    "count_ratios = (new_trades[change_date:end_date].mean() - new_trades[start_date:day_before_change].mean()) / new_trades[start_date:day_before_change].mean()\n",
    "liquidity_count_ratios = round(count_ratios*100, 2)\n",
    "liquidity_count_changes = pd.DataFrame({'Name': names,'Ticker': liquidity_count_ratios.index, 'Trades count movement (%)': liquidity_count_ratios.values})\n",
    "\n",
    "# Merge both data frame\n",
    "liquidity = pd.merge(liquidity_count_changes, liquidity_size_changes, on=[\"Ticker\", \"Name\"])\n",
    "liquidity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
