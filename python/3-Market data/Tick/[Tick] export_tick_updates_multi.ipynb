{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export tick updates from multiple assets using dedicated service - Python\n",
    "\n",
    "### Overview\n",
    "This sample demonstrates how to request from a dedicated raw data service **on-demand** tick by tick data `for a given instrument on multiple data sources`. \n",
    "\n",
    "### Inputs/outputs\n",
    "Tick data extraction sample requires instrument's identifier, date time intervals as per inputs and exports tick by tick data file. \n",
    "\n",
    "### Services used\n",
    "This sample uses *gRPC requests* in order to retrieve tick by tick dataset from the hosted service. The queried endpoint in this script are:\n",
    "* *TickUpdatesService*: to directly retrieve tick updates from the server.\n",
    "\n",
    "### Modules required\n",
    "1. Systemathics:\n",
    "    * *systemathics.apis.services.tick.v1*\n",
    "    * *systemathics.apis.type.shared.v1*\n",
    "    * *google.type*\n",
    "2. Open source:\n",
    "    * *googleapis-common-protos*\n",
    "    * *protobuf*\n",
    "    * *grpcio*\n",
    "    * *pandas*\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run tick updates multi asset extraction sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.9/site-packages (1.56.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.9/site-packages (3.20.0)\n",
      "Requirement already satisfied: grpcio in /opt/conda/lib/python3.9/site-packages (1.44.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.9/site-packages (from grpcio) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install googleapis-common-protos protobuf grpcio pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: systemathics.apis in /opt/conda/lib/python3.9/site-packages (0.9.99rc0)\n",
      "Requirement already satisfied: grpcio in /opt/conda/lib/python3.9/site-packages (from systemathics.apis) (1.44.0)\n",
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.9/site-packages (from systemathics.apis) (1.56.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.9/site-packages (from systemathics.apis) (3.20.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.9/site-packages (from grpcio->systemathics.apis) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install systemathics.apis --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import grpc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import google.type.date_pb2 as date\n",
    "import google.type.timeofday_pb2 as timeofday\n",
    "import google.type.dayofweek_pb2 as dayofweek\n",
    "import google.protobuf.duration_pb2 as duration\n",
    "import google.protobuf.wrappers_pb2 as wrappers\n",
    "import systemathics.apis.type.shared.v1.level_pb2 as level\n",
    "import systemathics.apis.type.shared.v1.identifier_pb2 as identifier\n",
    "import systemathics.apis.type.shared.v1.identifier_and_level_pb2 as identifier_and_level\n",
    "import systemathics.apis.type.shared.v1.constraints_pb2 as constraints\n",
    "import systemathics.apis.type.shared.v1.date_interval_pb2 as dateinterval\n",
    "import systemathics.apis.type.shared.v1.time_interval_pb2 as timeinterval\n",
    "import systemathics.apis.services.tick.v1.tick_updates_pb2 as tick_updates\n",
    "import systemathics.apis.services.tick.v1.tick_updates_pb2_grpc as tick_updates_service\n",
    "import systemathics.apis.helpers.token_helpers as token_helpers\n",
    "import systemathics.apis.helpers.channel_helpers as channel_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Retrieve authentication token\n",
    "The following code snippet sends authentication request and print token to console output in order to process the upcomming *gRPC queries*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IlpBV05FbDJfMF9zTDNUTklIdlN3SiJ9.eyJodHRwOi8vc2NoZW1hcy54bWxzb2FwLm9yZy93cy8yMDA1LzA1L2lkZW50aXR5L2NsYWltcy9lbWFpbGFkZHJlc3MiOiJvY3RhdmUuYmVsb3RAc3lzdGVtYXRoaWNzLmNvbSIsImlzcyI6Imh0dHBzOi8vZ2FueW1lZGUtZGV2LmV1LmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2MjRmZWE2NWJlODIzYzAwNmZlMzg2MzQiLCJhdWQiOlsiaHR0cHM6Ly9kZXYuZ2FueW1lZGUtZGV2IiwiaHR0cHM6Ly9nYW55bWVkZS1kZXYuZXUuYXV0aDAuY29tL3VzZXJpbmZvIl0sImlhdCI6MTY0OTQwNjA3NiwiZXhwIjoxNjUxOTk4MDc2LCJhenAiOiJubGp0SkhkRnJ1Z3VDY2ZacUVtZHEyMEtrMkM2dFduWSIsInNjb3BlIjoib3BlbmlkIHByb2ZpbGUgZW1haWwiLCJwZXJtaXNzaW9ucyI6WyJhZG1pbiIsImFydGVmYWN0cyIsImNoYW5nZXMiLCJjb21wb25lbnRzIiwiZGFpbHlfYmFycyIsImRhaWx5X2JvbGxpbmdlciIsImRhaWx5X2NtYSIsImRhaWx5X2VtYSIsImRhaWx5X21hY2QiLCJkYWlseV9wcmljZXMiLCJkYWlseV9yc2kiLCJkYWlseV9zbWEiLCJkYWlseV92b2xhdGlsaXR5IiwiZGFpbHlfdndhcHMiLCJkaXZpZGVuZHMiLCJpZGVudGlmaWVyX21hcHBpbmciLCJpbnRyYWRheV9iYXJzIiwiaW50cmFkYXlfYm9sbGluZ2VyIiwiaW50cmFkYXlfY21hIiwiaW50cmFkYXlfZW1hIiwiaW50cmFkYXlfbWFjZCIsImludHJhZGF5X3ByaWNlcyIsImludHJhZGF5X3JzaSIsImludHJhZGF5X3NtYSIsImludHJhZGF5X3ZvbGF0aWxpdHkiLCJpbnRyYWRheV92d2FwcyIsIm1lbW9zIiwic3BsaXRzIiwic3RhdGljX2RhdGEiLCJzdGF0aWNfc2VjdG9yIiwic3VzdGFpbmFiaWxpdHkiLCJ0aWNrX2JhcnMiLCJ0aWNrX2JvbGxpbmdlciIsInRpY2tfYm9vayIsInRpY2tfY21hIiwidGlja19jb25kaXRpb25zIiwidGlja19lbWEiLCJ0aWNrX3F1b3RlcyIsInRpY2tfcmF3IiwidGlja19zbWEiLCJ0aWNrX3RyYWRlcyIsInRpY2tfdHJhZGVzX2FuZF9ib29rIiwidGlja191cGRhdGVzIiwidGlja192d2FwIiwidG9wb2xvZ2llcyJdfQ.xI4XryUG6QLdripyVc613elyNPMZxn6FUAUKjTo8SFJKBNkqA-396H2AUu_sLF4NAhYSUfbODfCcTAp-lhqZJaCjJrnWfqvDRMIt0IuYpjd0Cy4UG1rWCKqCiw2RhPXpYfi4p0Kkecn-uabPLTaYXRILOHKTxgQwOL7zpELK-MCsflNjmnIvl1sR4UzFOYzvgB525EXVJNds73MqjaOtfa6h7cY8WUDEVgrab3_aRexj2YsAQkfPCEoEnoYAnvXdscnyGte6ijIQBaX8siiyjKXvanRQRHNIg_7YVm_isq8jr4SClkyBE2XewxjZy08h43DuWmbQyUOeyAGdSbDUXQ'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token = token_helpers.get_token()\n",
    "display(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create and process request\n",
    "To request *tick updates* service, we need to specify:\n",
    "* Instrument identifier\n",
    "* Time period selection: select start and end dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Instrument selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tha data is provided by ICE : let's use the ICE mapping codes to generate the identifier\n",
    "# The ICE ticker\n",
    "ticker = 'E:BNP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Time period delimitation\n",
    "The following code setups time constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date intervals (we are using Google date format)\n",
    "# Full order book data avaialble (sample) : from 2021-11-01 to 2021-11-12\n",
    "date_interval = dateinterval.DateInterval(\n",
    "    start_date = date.Date(year = 2021, month = 11, day = 1), \n",
    "    end_date = date.Date(year = 2021, month = 11, day = 1)\n",
    ")\n",
    "\n",
    "# Build the tick quotes request time interval (we are using Google date time format)\n",
    "# UTC time zone\n",
    "time_interval = timeinterval.TimeInterval(\n",
    "    start_time = timeofday.TimeOfDay(hours = 12, minutes = 0, seconds = 0), \n",
    "    end_time = timeofday.TimeOfDay(hours = 20, minutes = 30, seconds = 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Request creation\n",
    "The following code snippet creates *gRPC client*, process request and returns the request reply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate constraints based on the previous time selection\n",
    "my_constraints = constraints.Constraints(\n",
    "    date_intervals = [date_interval],\n",
    "    time_intervals = [time_interval],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets create the market data request and instantiate the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to stream the ticks from those two Euronext sources (specific to provider \"ICE\")\n",
    "my_provider = 'ICE'\n",
    "identifier_1 = identifier_and_level.IdentifierAndLevel(ticker = ticker,exchange = '787',level = level.LEVEL_TRADES, provider = wrappers.StringValue(value=my_provider)  )\n",
    "identifier_2 = identifier_and_level.IdentifierAndLevel(ticker = ticker,exchange = 'EQUITY_L2_973', level = level.LEVEL_TRADES_AND_BOOK, provider = wrappers.StringValue(value=my_provider) )\n",
    "my_identifiers = [identifier_1, identifier_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the tick updates request\n",
    "request = tick_updates.TickUpdatesRequest(\n",
    "    identifiers = my_identifiers,\n",
    "    constraints = my_constraints,\n",
    "    adjustment = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Process request and export results\n",
    "\n",
    "We define beforehand some functions to get a better display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get side from code\n",
    "def get_side(side):\n",
    "    if side == 0:\n",
    "        return 'SIDE_UNSPECIFIED'\n",
    "    elif side ==1:\n",
    "        return 'SIDE_BID'\n",
    "    elif side ==1:\n",
    "        return 'SIDE_ASK'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Get action from code\n",
    "def get_action(action):\n",
    "    if action == 0:\n",
    "        return 'ACTION_UNSPECIFIED'\n",
    "    elif action ==1:\n",
    "        return 'ACTION_SET'\n",
    "    elif action ==2:\n",
    "        return 'ACTION_CLEAR'\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "# Get field name type from code\n",
    "def get_field_name(field):\n",
    "    if field == 9:\n",
    "        return 'FIELD_TRADE_PRICE'\n",
    "    elif field ==10:\n",
    "        return 'FIELD_TRADE_SIZE'\n",
    "    elif field ==11:\n",
    "        return 'FIELD_TRADING_CONDITION'\n",
    "    elif field ==25:\n",
    "        return 'FIELD_TRADE_ID'\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "# Get field type type from code\n",
    "def get_field_type(field):\n",
    "    if field == 9:\n",
    "        return 'double_value'\n",
    "    elif field ==10:\n",
    "        return 'long_value'\n",
    "    elif field ==11 or field == 25:\n",
    "        return 'string_value'\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "# Get field value type from update\n",
    "def get_field_value(update):\n",
    "    my_type = get_field_type(update.field)\n",
    "    if my_type == 'double_value':\n",
    "        return update.double_value\n",
    "    elif my_type == 'long_value':\n",
    "        return update.long_value\n",
    "    elif my_type == 'string_value':\n",
    "        return update.string_value\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code snippet, we request tick updates for the given instruments.\n",
    "The streamed response is exported on the fly in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Done exporting ----- \n",
      "Updates found: 269772\n",
      "--> Mappings found: 1\n",
      "--> MBO updates found: 258387\n",
      "--> MBL updates found: 0\n",
      "--> Fields updates found: 11384\n",
      "Check export in E:BNP_tick_updates.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import timedelta\n",
    "\n",
    "filename = '{}_tick_updates.csv'.format(ticker)\n",
    "total_messages,mbo_count,mbl_count,fields_count,mappings_count = 0,0,0,0,0\n",
    "\n",
    "with open(filename, mode='w') as tick_uptades_file:\n",
    "    tick_uptades_writer = csv.writer(tick_uptades_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    # write 1rst row\n",
    "    tick_uptades_writer.writerow(['Timestamp', 'Type', 'Mapping', 'Action', 'Side', 'Price', 'Size', 'Depth', 'OrderId', 'Condition', 'Reset', 'FieldName', 'FieldType', 'FieldValue', 'MessageNumber'])\n",
    "    try:\n",
    "        # open a gRPC channel\n",
    "        with channel_helpers.get_grpc_channel() as channel:\n",
    "\n",
    "            # instantiate the tick raw service\n",
    "            service = tick_updates_service.TickUpdatesServiceStub(channel)\n",
    "\n",
    "            # process the tick raw request\n",
    "            for current in service.TickUpdates(request=request, metadata=[('authorization', token)]):\n",
    "                \n",
    "                total_messages+=1\n",
    "                if len(current.mapping.values) > 0: # mapping\n",
    "                    my_mapping = current.mapping\n",
    "                    mappings_count +=1\n",
    "                    \n",
    "                if current.fields_updates.time_stamp.seconds > 0: # fields update\n",
    "                    test_fieldupdate = current\n",
    "                    fields_count+=1\n",
    "                    \n",
    "                    str_timestamp = datetime.fromtimestamp(current.fields_updates.time_stamp.seconds) + timedelta(microseconds = current.fields_updates.time_stamp.nanos/1000)\n",
    "                    str_type = 'FLD'\n",
    "                    str_mapping = current.fields_updates.mapping\n",
    "                    str_reset =current.fields_updates.reset\n",
    "                    for update in current.fields_updates.updates:\n",
    "                        str_action =''\n",
    "                        str_side =''\n",
    "                        str_price =''\n",
    "                        str_size =''\n",
    "                        str_depth =''\n",
    "                        str_orderid =''\n",
    "                        str_condition =''\n",
    "                        str_fieldname =get_field_name(update.field)\n",
    "                        str_fieldtype =get_field_type(update.field)\n",
    "                        str_fieldvalue =get_field_value(update)\n",
    "                        str_messagenumber = total_messages\n",
    "                        tick_uptades_writer.writerow([str_timestamp, str_type, str_mapping, str_action, str_side, str_price, str_size, str_depth, str_orderid, str_condition, str_reset, str_fieldname, str_fieldtype, str_fieldvalue, str_messagenumber])\n",
    "\n",
    "                    \n",
    "                if current.mbl_book_updates.time_stamp.seconds > 0: # mbl update\n",
    "                    mbl_count+=1\n",
    "                    test_mbl = current\n",
    "                    \n",
    "                    str_timestamp = datetime.fromtimestamp(current.mbl_book_updates.time_stamp.seconds) + timedelta(microseconds = current.mbl_book_updates.time_stamp.nanos/1000)\n",
    "                    str_type = 'MBL'\n",
    "                    str_mapping = current.mbl_book_updates.mapping\n",
    "                    str_action =get_action(current.mbl_book_updates.updates[0].action)\n",
    "                    str_side =get_side(current.mbl_book_updates.updates[0].side)\n",
    "                    str_price =current.mbl_book_updates.updates[0].price.value\n",
    "                    str_size =current.mbl_book_updates.updates[0].size.value\n",
    "                    str_depth =current.mbl_book_updates.updates[0].depth\n",
    "                    str_orderid =''\n",
    "                    str_condition =''\n",
    "                    str_reset =current.mbl_book_updates.reset\n",
    "                    str_fieldname =''\n",
    "                    str_fieldtype =''\n",
    "                    str_fieldvalue =''\n",
    "                    str_messagenumber = total_messages\n",
    "                    tick_uptades_writer.writerow([str_timestamp, str_type, str_mapping, str_action, str_side, str_price, str_size, str_depth, str_orderid, str_condition, str_reset, str_fieldname, str_fieldtype, str_fieldvalue, str_messagenumber])\n",
    "                                    \n",
    "                if current.mbo_book_updates.time_stamp.seconds > 0: # mbo update\n",
    "                    mbo_count+=1\n",
    "                    test_mbo = current\n",
    "                    \n",
    "                    str_timestamp = datetime.fromtimestamp(current.mbo_book_updates.time_stamp.seconds) + timedelta(microseconds = current.mbo_book_updates.time_stamp.nanos/1000)\n",
    "                    str_type = 'MBO'\n",
    "                    str_mapping = current.mbo_book_updates.mapping\n",
    "                    str_action =get_action(current.mbo_book_updates.updates[0].action)\n",
    "                    str_side =get_side(current.mbo_book_updates.updates[0].side)\n",
    "                    str_price =current.mbo_book_updates.updates[0].price.value\n",
    "                    str_size =current.mbo_book_updates.updates[0].size.value\n",
    "                    str_depth =''\n",
    "                    str_orderid =current.mbo_book_updates.updates[0].order_id\n",
    "                    str_condition =current.mbo_book_updates.updates[0].condition\n",
    "                    str_reset =current.mbo_book_updates.reset\n",
    "                    str_fieldname =''\n",
    "                    str_fieldtype =''\n",
    "                    str_fieldvalue =''\n",
    "                    str_messagenumber = total_messages\n",
    "                    tick_uptades_writer.writerow([str_timestamp, str_type, str_mapping, str_action, str_side, str_price, str_size, str_depth, str_orderid, str_condition, str_reset, str_fieldname, str_fieldtype, str_fieldvalue, str_messagenumber])\n",
    "                                  \n",
    "    except grpc.RpcError as e:\n",
    "        display(e.code().name)\n",
    "        display(e.details())\n",
    "\n",
    "# Some display\n",
    "print('----- Done exporting ----- ')\n",
    "print('Updates found: {}'.format(total_messages)) \n",
    "print('--> Mappings found: {}'.format(mappings_count)) \n",
    "print('--> MBO updates found: {}'.format(mbo_count)) \n",
    "print('--> MBL updates found: {}'.format(mbl_count)) \n",
    "print('--> Fields updates found: {}'.format(fields_count)) \n",
    "print('Check export in {}'.format(filename)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
