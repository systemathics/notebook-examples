{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor data normalization (FUTURES) - Python\n",
    "\n",
    "### Overview\n",
    "Tick count indicator enables to monitor data collection, normalization and storage. Coupled with other monitoring metrics, tick count represents a rich monitoring tool to ensure data completion and storage quality.\n",
    "\n",
    "### Inputs/outputs\n",
    "Data normalization monitoring sample takes a list of instrument identifiers (futures) a sper input and returns a set of metrics such as:\n",
    "* Total tick cout for each instrument\n",
    "* Total entries used to compute tick count based on the chosen time granularity\n",
    "* First tick date\n",
    "* Last tick date\n",
    "* Missing days: today - last tick date\n",
    "\n",
    "### Services used\n",
    "This sample uses *gRPC requests* in order to retrieve ticks and static data objects from the dedicated hosted services. The queried endpoint in this script are:\n",
    "* *StaticDataService*: to directly retrieve static data objects from the server\n",
    "* *TopologiesService*: to directly retrieve ticks objects from the server\n",
    "\n",
    "### Modules required\n",
    "1. Systemathics packages:\n",
    "    * *systemathics.apis.services.static_data.v1*\n",
    "    * *systemathics.apis.services.topology.v1*\n",
    "    * *systemathics.apis.type.shared.v1*\n",
    "    * *google.type*\n",
    "2. Open source packages\n",
    "    * *googleapis-common-protos*\n",
    "    * *protobuf*\n",
    "    * *grpcio*\n",
    "    * *pandas*\n",
    "    * *matpotlib* as per display package\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run futures futures data normalization sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install googleapis-common-protos protobuf grpcio pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install systemathics.apis --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import grpc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import google.type.date_pb2 as date\n",
    "import systemathics.apis.type.shared.v1.level_pb2 as level\n",
    "import systemathics.apis.type.shared.v1.identifier_pb2 as identifier\n",
    "import systemathics.apis.services.topology.v1.topologies_pb2 as topologies\n",
    "import systemathics.apis.services.topology.v1.topologies_pb2_grpc as topologies_service\n",
    "import systemathics.apis.services.static_data.v1.static_data_pb2 as static_data\n",
    "import systemathics.apis.services.static_data.v1.static_data_pb2_grpc as static_data_service\n",
    "import systemathics.apis.helpers.token_helpers as token_helpers\n",
    "import systemathics.apis.helpers.channel_helpers as channel_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Retrieve authentication token\n",
    "The following code snippet sends authentication request and print token to console output in order to process the upcomming *gRPC queries*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token_helpers.get_token()\n",
    "display(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create and process request\n",
    "To request *TopologiesService*, we need to specify:\n",
    "* Instrument identifier\n",
    "* Time period selection: select start and end dates\n",
    "* Topology request parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Instrument selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set instrument identifier: exchange + ticker + sources\n",
    "contractexchange_array = [['CC', 'IFUS',675],\n",
    "                        ['KC', 'IFUS',675],\n",
    "                        ['BRN', 'IFEU',756],\n",
    "                        ['WBS', 'IFEU',756],\n",
    "                        ['I', 'IFLL',890],\n",
    "                        ['W', 'IFLX',890]]\n",
    "length = len(contractexchange_array)\n",
    "colors = {\n",
    "  675: \"green\",\n",
    "  756 : \"blue\",\n",
    "  890: \"red\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Retrieve front future contract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippets enable to:\n",
    "* Retrieve the matching futures (all maturities) for a given future input contract code\n",
    "* For each input contract code, select the front future among the previously returned futures (all maturities)\n",
    "\n",
    "If the front future is missing, we select the most recent future contract (expired)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to handle static data request creation for each instrument\n",
    "def get_staticdata_request(contract):\n",
    "    data_request = static_data.StaticDataRequest( asset_type = static_data.AssetType.ASSET_TYPE_FUTURE)\n",
    "    data_request.future_contract.value = contract\n",
    "    data_request.count.value = 1000\n",
    "    return data_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_futures=[]\n",
    "\n",
    "# credentials\n",
    "credentials = grpc.ssl_channel_credentials()\n",
    "\n",
    "# iterate all future contracts\n",
    "for i in range(length):\n",
    "    contract = contractexchange_array[i][0]\n",
    "    try:\n",
    "        # open a gRPC channel\n",
    "        with channel_helpers.get_grpc_channel() as channel:  \n",
    "            # instantiate the static data request\n",
    "            service = static_data_service.StaticDataServiceStub(channel)\n",
    "            request = get_staticdata_request(contract)\n",
    "            \n",
    "            # process the static data request\n",
    "            response = service.StaticData(request = request, metadata = [('authorization', token)])\n",
    "            sorted_futures = sorted(response.futures, key=lambda x: (x.maturity.year, x.maturity.month))\n",
    "            futures_count = len(sorted_futures)\n",
    "            print('Found {0} futures for contract {1}: '.format(futures_count, contract))\n",
    "            all_futures.append(sorted_futures)\n",
    "    except grpc.RpcError as e:\n",
    "        display(e.code().name)\n",
    "        display(e.details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the **front** for each future contract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "tickerexchange_array = []\n",
    "\n",
    "# iterate all future contracts\n",
    "for i in range(length):\n",
    "    source = contractexchange_array[i][2] #keep source for later\n",
    "    contract = contractexchange_array[i][0]\n",
    "    found = False\n",
    "    \n",
    "    # iterate all future maturities\n",
    "    for future in all_futures[i]:\n",
    "        current_future = future\n",
    "        maturity = datetime(current_future.maturity.year, current_future.maturity.month,current_future.maturity.day)\n",
    "        ticker = current_future.identifier.ticker\n",
    "        exchange = current_future.identifier.exchange\n",
    "        \n",
    "        # check if we reached the front\n",
    "        if (maturity > today):\n",
    "            tickerexchange_array.append([ticker, exchange, source])\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    # if we didn't find any front for the current contract, we'll then chose the last contract\n",
    "    if not found:\n",
    "        tickerexchange_array.append([ticker, exchange, source])\n",
    "        print('Could not find front for contract {0} - Selected last future with ticker {1}, maturity {2::%Y/%m/%d}'.format(contract, ticker, maturity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying our selected tickers\n",
    "print(tickerexchange_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Topology parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set topology time granularity (daily, weekly...)\n",
    "granularity = topologies.TOPOLOGY_GRANULARITY_DAILY\n",
    "\n",
    "# set level: Trades or Trades and Book\n",
    "my_level = level.LEVEL_TRADES_AND_BOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Request creation\n",
    "The following code snippet creates *gRPC client*, process request and ensure that the reply is not empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method to handle topologies request creation for each instrument\n",
    "def get_topologies_request(ticker, exchange, granularity, level):\n",
    "    request = topologies.TopologiesRequest(identifier = identifier.Identifier(exchange = exchange, ticker = ticker),\n",
    "                                           granularity = granularity,\n",
    "                                           level = level)\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all topologies requests\n",
    "credentials = grpc.ssl_channel_credentials()\n",
    "futures_responses =[]\n",
    "today = datetime.today()\n",
    "      \n",
    "# iterate all instrument identifiers: exhange/ticker pairs\n",
    "for i in range(length):\n",
    "    with channel_helpers.get_grpc_channel() as channel:  \n",
    "\n",
    "        # instantiate the topologies service\n",
    "        ticker = tickerexchange_array[i][0]\n",
    "        exchange = tickerexchange_array[i][1]\n",
    "        request = get_topologies_request(ticker, exchange, granularity, my_level)\n",
    "        service = topologies_service.TopologiesServiceStub(channel)\n",
    "\n",
    "        # process the topologies request\n",
    "        response = service.Topologies(\n",
    "            request=request, \n",
    "            metadata = [('authorization', token)]\n",
    "        )\n",
    "        \n",
    "        #store\n",
    "        futures_responses.append(response)\n",
    "        \n",
    "# get tick count data\n",
    "print(\"Total asset requests: \", len(futures_responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Retreive data\n",
    "The following code snippet enables to export computed metrics to *csv file*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# process all topologies responses\n",
    "today = datetime.today()\n",
    "filename = 'alltime_futures_dashboard_{0:%Y%m%d}.csv'.format(today)\n",
    "\n",
    "with open(filename, mode='w') as topologies_futures_file:\n",
    "    topologies_futures_writer = csv.writer(topologies_futures_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    # write 1rst row\n",
    "    topologies_futures_writer.writerow(['Ticker', 'Exchange', 'Source', 'Entries' ,'Total_ticks', 'First_tick', 'Last_tick', 'Missing_days'])\n",
    "            \n",
    "    # Iterate all exhange/ticker pairs\n",
    "    for i in range(length):\n",
    "\n",
    "        response = futures_responses[i]    \n",
    "        # instantiate the topologies service\n",
    "        ticker = tickerexchange_array[i][0]\n",
    "        exchange = tickerexchange_array[i][1]\n",
    "\n",
    "        entries_count = len(response.entries)\n",
    "        tick_counts = sum([entry.ticks_count for entry in response.entries])\n",
    "        first_date = datetime(response.entries[0].begin.year, response.entries[0].begin.month, response.entries[0].begin.day)\n",
    "        last_date = datetime(response.entries[-1].end.year, response.entries[-1].end.month, response.entries[-1].end.day)\n",
    "        missing_days = (today- last_date).days\n",
    "        source = tickerexchange_array[i][2]\n",
    "        print(\"Total entries for {0}-{1} ({2}) \\t: {3} \\t| total ticks count: {4} \\t | b: {5:%Y/%m/%d} - {6:%Y/%m/%d} \\t| Missing days: {7}\".format(ticker, exchange, source ,entries_count, tick_counts, first_date, last_date,missing_days))\n",
    "        topologies_futures_writer.writerow([ticker,exchange, source, entries_count, tick_counts, '{0:%Y/%m/%d}'.format(first_date), '{0:%Y/%m/%d}'.format(last_date), missing_days])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Plot data normalization overview\n",
    "The following code snippet enables to plot data normalization metrics per instrument in a single window to give an overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 3\n",
    "num_cols = 2\n",
    "fig,axs = plt.subplots(num_rows,num_cols, figsize=(30,10))\n",
    "for i in range(length):\n",
    "    ticker = tickerexchange_array[i][0]\n",
    "    exchange = tickerexchange_array[i][1]\n",
    "    source = tickerexchange_array[i][2]\n",
    "    counts = [entry.ticks_count for entry in futures_responses[i].entries]\n",
    "    dates = [datetime(year=entry.begin.year,day=entry.begin.day, month=entry.begin.month) for entry in futures_responses[i].entries]\n",
    "    col = i//num_rows\n",
    "    row = i%num_rows\n",
    "    axs[row, col].bar(dates, counts, color=colors[source])\n",
    "    axs[row, col].set_title('{0}-{1} ({2})'.format(ticker, exchange, source))\n",
    "    \n",
    "# set the spacing between subplots\n",
    "plt.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=1.2)\n",
    "\n",
    "# add subtitle\n",
    "plt.suptitle(\"Tick counts for all selected futures\", size=\"20\")\n",
    "\n",
    "# plot\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Plot data normalization details\n",
    "The following code snippet enables to plot data normalization metrics per instrument in a multiple windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One figure for each asset\n",
    "for i in range(length):\n",
    "    ticker = tickerexchange_array[i][0]\n",
    "    exchange = tickerexchange_array[i][1]\n",
    "    source = tickerexchange_array[i][2]\n",
    "    counts = [entry.ticks_count for entry in futures_responses[i].entries]\n",
    "    dates = [datetime(year=entry.begin.year,day=entry.begin.day, month=entry.begin.month) for entry in futures_responses[i].entries]\n",
    "    \n",
    "    # plot\n",
    "    fig,ax = plt.subplots(1,1,figsize=(25,10))\n",
    "    ax.bar(dates,counts, color=colors[source])\n",
    "    plt.xlabel(\"Date\",size=\"20\")\n",
    "    plt.ylabel(\"Tick count\",size=\"20\")\n",
    "    plt.title(\"Tick count for {0}-{1} | source: {2}\".format(ticker,exchange, source),size=\"20\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
