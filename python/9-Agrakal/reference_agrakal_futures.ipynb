{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor agrakal daily data (FUTURES) - Python\n",
    "\n",
    "### Overview\n",
    "\n",
    "This sample makes the inventory of the reference futures for agrakal\n",
    "\n",
    "### Services used\n",
    "This sample uses *gRPC requests* in order to retrieve daily data from the dedicated hosted service. The queried endpoint in this script are:\n",
    "* StaticData: to get the intrument identifier from the input\n",
    "* Bars: to get market data for each instrument\n",
    "\n",
    "### Modules required\n",
    "1. Systemathics packages:\n",
    "    * *systemathics.apis*\n",
    "2. Open source packages\n",
    "    * *googleapis-common-protos*\n",
    "    * *protobuf*\n",
    "    * *grpcio*\n",
    "    * *pandas*\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run index agrakal daily reference data sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install googleapis-common-protos protobuf grpcio pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install systemathics.apis --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import grpc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta \n",
    "import google.type.date_pb2 as date\n",
    "import google.type.timeofday_pb2 as timeofday\n",
    "import google.type.dayofweek_pb2 as dayofweek\n",
    "import google.protobuf.duration_pb2 as duration\n",
    "import google.protobuf as pb\n",
    "\n",
    "import systemathics.apis.type.shared.v1.identifier_pb2 as identifier\n",
    "import systemathics.apis.type.shared.v1.constraints_pb2 as constraints\n",
    "import systemathics.apis.type.shared.v1.date_interval_pb2 as dateinterval\n",
    "import systemathics.apis.type.shared.v1.time_interval_pb2 as timeinterval\n",
    "import systemathics.apis.services.static_data.v1.static_data_pb2 as static_data\n",
    "import systemathics.apis.services.static_data.v1.static_data_pb2_grpc as static_data_service\n",
    "import systemathics.apis.services.tick_analytics.v1.tick_bars_pb2 as tick_bars\n",
    "import systemathics.apis.services.tick_analytics.v1.tick_bars_pb2_grpc as tick_bars_service\n",
    "import systemathics.apis.helpers.token_helpers as token_helpers\n",
    "import systemathics.apis.helpers.channel_helpers as channel_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Retrieve authentication token\n",
    "The following code snippet sends authentication request and print token to console output in order to process the upcomming *gRPC queries*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token_helpers.get_token()\n",
    "display(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Specify parameters\n",
    "To request *BarsService* we need to specify the **Instrument identifier** and some **Time Constraints**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Instrument selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set instrument identifier: exchange + ticker\n",
    "tickerexchange_array = [['FESX', 'XEUR'], #Euro STOXX 50 Future\n",
    "                        ['FDAX', 'XEUR'], # DAX Future\n",
    "                        ['DX', 'IFUS'], # US Dollar Index Future\n",
    "                        ['ZB', 'XCBT'] # US Treasury Bond Future\n",
    "                       ]\n",
    "length = len(tickerexchange_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Time constraints and bars parameters selection\n",
    "Specify the time constraints such as bar duration, first date, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(year=2021,month=1,day=1)\n",
    "end = datetime.today()\n",
    "start_time = timeofday.TimeOfDay(hours = 10, minutes = 0, seconds = 0)\n",
    "end_time = timeofday.TimeOfDay(hours = 17, minutes = 0, seconds = 0)\n",
    "offset = duration.Duration(seconds = start_time.hours*3600)\n",
    "sampling = 3600*(end_time.hours - start_time.hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define necessary methods\n",
    "In this part we define the methods that will be used later on for the full workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1: Future selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a method to request all futures from a given contract code\n",
    "# input: contract\n",
    "# output: static data request\n",
    "def get_static_data_request(contract):\n",
    "    # generate request and add filter values\n",
    "    data_request = static_data.StaticDataRequest( asset_type = static_data.AssetType.ASSET_TYPE_FUTURE)\n",
    "    data_request.future_contract.value = contract\n",
    "    data_request.count.value = 1000\n",
    "    return data_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a method to request static data for the given future and return all futures which are not expired yet \n",
    "# input: contract, start date (for filtering)\n",
    "# output: list of filtered futures as returned by the API\n",
    "def get_sorted_futures(contract, start_date):\n",
    "    data_request = get_static_data_request(contract)\n",
    "    try:\n",
    "        # open a gRPC channel\n",
    "        with channel_helpers.get_grpc_channel() as channel:  \n",
    "\n",
    "            rpc_service = static_data_service.StaticDataServiceStub(channel)\n",
    "            metadata = [('authorization', token)]\n",
    "\n",
    "            # Process the request\n",
    "            response = rpc_service.StaticData(request=data_request, metadata=metadata)\n",
    "            \n",
    "        # Sort futures : fix this issue = cant filter\n",
    "        #sorted_futures = response.futures\n",
    "        sorted_futures = sorted(response.futures, key=lambda x: (x.maturity.year, x.maturity.month))\n",
    "\n",
    "        # Filter according to date\n",
    "        selected_futures=[]\n",
    "        for future in sorted_futures:\n",
    "            maturity = datetime(future.maturity.year, future.maturity.month,future.maturity.day)\n",
    "            if maturity >= start_date:\n",
    "                selected_futures.append(future)\n",
    "        return selected_futures\n",
    "    except grpc.RpcError as e:\n",
    "        display(e.code().name)\n",
    "        display(e.details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a method returning the front future for a given date\n",
    "# input: list of futures + current date\n",
    "# output: front future\n",
    "def get_front(futures, time):\n",
    "    for future in futures:\n",
    "        maturity = datetime(future.maturity.year, future.maturity.month,future.maturity.day)\n",
    "        #print(\"{0} vs {1}\".format(maturity, time))\n",
    "        if maturity > time:\n",
    "            return future\n",
    "    # default\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a method returning the front future for a given date\n",
    "# input: list of futures + current date\n",
    "# output: front future\n",
    "def get_back(futures, time):\n",
    "    skipped_front = False\n",
    "    for future in futures:\n",
    "        maturity = datetime(future.maturity.year, future.maturity.month,future.maturity.day)\n",
    "        #print(\"{0} vs {1}\".format(maturity, time))\n",
    "        if maturity > time:\n",
    "            if skipped_front:\n",
    "                return future\n",
    "            else:\n",
    "                skipped_front = True\n",
    "    # default\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.2: Bars request processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a method returning intraday bars for given identifier (other parameters are locked from the notebook inputs)\n",
    "def generate_bars_parameters(start_time, end_time, selected_futures):\n",
    "    # Get all futures from given start date to end date\n",
    "    current_time = start_time\n",
    "    identifiers, starts, ends = [],[],[]\n",
    "    while(current_time<end_time):\n",
    "        front = get_front(selected_futures, current_time)\n",
    "        maturity = datetime(front.maturity.year, front.maturity.month,front.maturity.day)\n",
    "\n",
    "        # add data\n",
    "        identifiers.append(front.identifier)\n",
    "        starts.append(current_time)\n",
    "\n",
    "        # prepare to skip to next future if needed\n",
    "        current_time = maturity + timedelta(days=1)\n",
    "        ends.append(front.maturity)\n",
    "\n",
    "        \n",
    "        \n",
    "    # store in a dataframe and visualize start/end dates\n",
    "    d = {'Identifier': identifiers, 'Start': starts, 'End': ends}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a method that creates a request to the intraday bars endpoint with the given inputs\n",
    "def get_bars_request(identifier, start, end, sampling, start_time, end_time, offset):\n",
    "    \n",
    "    # --> Sampling\n",
    "    sampling = sampling\n",
    "    \n",
    "    # --> Constraints : specify the start/close date, a time interval, and filtered days.\n",
    "\n",
    "    # Set the start/close date\n",
    "    start_date = date.Date(year = start.year, month =start.month, day = start.day)\n",
    "    end_date = date.Date(year = end.year, month =end.month, day = end.day)\n",
    "    date_interval = dateinterval.DateInterval(start_date = start_date, end_date= end_date)\n",
    "\n",
    "    # Set days to exclude\n",
    "    excluded_days = [ dayofweek.SATURDAY, dayofweek.SUNDAY ]\n",
    "    \n",
    "    time_interval = timeinterval.TimeInterval(\n",
    "        start_time = start_time, \n",
    "        end_time = end_time)\n",
    "\n",
    "    # Constraints: no need time interval\n",
    "    constraint = constraints.Constraints(\n",
    "        date_intervals = [date_interval],\n",
    "        time_intervals = [time_interval],\n",
    "        excluded_days = excluded_days,\n",
    "        excluded_dates = [])\n",
    "    \n",
    "    request = tick_bars.TickBarsRequest(identifier = identifier,\n",
    "                                    field = tick_bars.BAR_PRICE_TRADE,\n",
    "                                    sampling = duration.Duration(seconds = sampling),\n",
    "                                    constraints = constraint,\n",
    "                                    offset = offset)\n",
    "    return request\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a method returning intraday bars for given identifier (other parameters are locked from the notebook inputs)\n",
    "def get_intraday_bars(identifier, start_date, end_date):\n",
    "    my_bars_request = get_bars_request(identifier, start_date, end_date, sampling, start_time, end_time, offset)\n",
    "\n",
    "    # open a gRPC channel\n",
    "    with channel_helpers.get_grpc_channel() as channel:  \n",
    "\n",
    "        # instantiate the tick bars service\n",
    "        bars_service = tick_bars_service.TickBarsServiceStub(channel)\n",
    "\n",
    "        # process the tick bars request\n",
    "        bars = []\n",
    "        metadata = [('authorization', token)]\n",
    "        for bar in bars_service.TickBars(request=my_bars_request, metadata=metadata):\n",
    "                bars.append(bar)\n",
    "    return bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.3: Bars export methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export the given ticker from given dictionary in a csv\n",
    "def export_bars(bars_dict, ticker):\n",
    "    dates=[datetime.fromtimestamp(b.time_stamp.seconds) for b in bars_dict[ticker]]\n",
    "    opens = [b.open for b in bars_dict[ticker]]\n",
    "    highs = [b.high for b in bars_dict[ticker]]\n",
    "    lows = [b.low for b in bars_dict[ticker]]\n",
    "    closes = [b.close for b in bars_dict[ticker]]\n",
    "    volumes = [ts.volume for ts in bars_dict[ticker]]\n",
    "    counts = [ts.count for ts in bars_dict[ticker]]\n",
    "    vwaps = [ts.vwap for ts in bars_dict[ticker]]\n",
    "\n",
    "    # create a pandas dataframe with: dates, bars and ticks count used for each bar\n",
    "    d = {'Date': dates, 'Open': opens, 'High': highs, 'Low' : lows,'Close': closes, 'Volume': volumes, 'Count': counts, 'Vwap': vwaps}\n",
    "    df_export = pd.DataFrame(data=d)\n",
    "\n",
    "    filename = 'Export/Future/{0}_bars.csv'.format(ticker)\n",
    "    df_export.to_csv(filename, index=False)\n",
    "    print(\"Exporting {0} bars to {1} ...\".format(ticker,filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export the given dictionary in a csv (all futures are joined)\n",
    "def export_joined_bars(bars_dict):\n",
    "    # Extract contract name\n",
    "    tmp = list(bars_dict.keys())[0]\n",
    "    contract = tmp[:len(tmp)-3]\n",
    "    \n",
    "    # process\n",
    "    dates, opens, highs,lows,closes, volumes,counts, vwaps,tickers = [],[],[],[],[],[],[],[],[]\n",
    "    for key in bars_dict.keys():\n",
    "        dates=  dates + [datetime.fromtimestamp(b.time_stamp.seconds) for b in bars_dict[key]]\n",
    "        opens = opens + [b.open for b in bars_dict[key]]\n",
    "        highs =  highs + [b.high for b in bars_dict[key]]\n",
    "        lows =lows+ [b.low for b in bars_dict[key]]\n",
    "        closes = closes+[b.close for b in bars_dict[key]]\n",
    "        volumes =volumes+ [ts.volume for ts in bars_dict[key]]\n",
    "        counts = counts+[ts.count for ts in bars_dict[key]]\n",
    "        vwaps =vwaps+ [ts.vwap for ts in bars_dict[key]]\n",
    "        tickers =tickers+ [key]*len(bars_dict[key])\n",
    "    \n",
    "    # create a pandas dataframe with: dates, bars and ticks count used for each bar\n",
    "    d = {'Date': dates, 'Open': opens, 'High': highs, 'Low' : lows,'Close': closes, 'Volume': volumes, 'Count': counts, 'Vwap': vwaps, 'Ticker': tickers}\n",
    "    df_export = pd.DataFrame(data=d)\n",
    "\n",
    "    filename = 'Export/Future/Joined_bars/{0}_bars.csv'.format(contract)\n",
    "    df_export.to_csv(filename, index=False)\n",
    "    print(\"Exporting joined {0} bars to {1} ...\".format(contract,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.4: Complete workflow methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method runs the full process to export bars\n",
    "def run_full_process(contract,start,end):\n",
    "    # generate future list, SORTED, + FILTERED (expired ones are removed)\n",
    "    my_futures = get_sorted_futures(contract, start)\n",
    "    print(\"Found {0} futures for contract code {1} from {2} to {3}\".format(len(my_futures),contract, start,end))\n",
    "    \n",
    "    \n",
    "    # Generate bars parameters: get front\n",
    "    bars_df = generate_bars_parameters(start, end, my_futures)\n",
    "    bars_df.head(3)\n",
    "    \n",
    "    # --> iterate all futures and request for bars, then store in a dictionary\n",
    "    bars_dict = {}\n",
    "    for i in range(len(bars_df.index)):\n",
    "        identifier = bars_df['Identifier'][i]\n",
    "        first = bars_df['Start'][i]\n",
    "        last = bars_df['End'][i]\n",
    "        bars = get_intraday_bars(identifier,first , last)\n",
    "        bars_dict[identifier.ticker] = bars\n",
    "        print('Retrieved {0} bar entries for {1} between {2:%Y/%m/%d} and {3}'.format(len(bars), identifier.ticker, first, last))\n",
    "    \n",
    "    \n",
    "    # --> Export individual bars (for each asset = each key in the dictionary)\n",
    "    for key in bars_dict.keys():\n",
    "        export_bars(bars_dict, key)\n",
    "        \n",
    "    # --> Export joined bars in a single file\n",
    "    export_joined_bars(bars_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Process each future separately\n",
    "In this part we'll use the previously defined methods to create a continuous bar series for the given assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.1: Test for WBS: One shot run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = 'WBS'\n",
    "run_full_process(contract,start,end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.2: Test for WBS: step by step\n",
    "This example reproduces the 'one-shot' process for continuous bars creation and gives details about the different steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instrument selection\n",
    "contract = 'DX'\n",
    "\n",
    "# Query static data and filter expired futures\n",
    "my_futures = get_sorted_futures(contract, start) # get futures\n",
    "\n",
    "#for f in my_futures:\n",
    "#    print(\"{0}-{1}\".format(f.maturity.year,f.maturity.month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bars parameters for following bars requests\n",
    "bars_df = generate_bars_parameters(start,end,  my_futures) # generate bars_start/end time + identifiers\n",
    "bars_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request bars for each instrument according to the date constraints generated above\n",
    "# results are stored in a dictionary indexed by instrument tickers: (ex FESXH18)\n",
    "bars_dict = {}\n",
    "\n",
    "# iterate all futures\n",
    "for i in range(len(bars_df.index)):\n",
    "    identifier = bars_df['Identifier'][i]\n",
    "    first = bars_df['Start'][i]\n",
    "    last = bars_df['End'][i]\n",
    "    bars = get_intraday_bars(identifier,first , last)\n",
    "    bars_dict[identifier.ticker] = bars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export bars for each instrument\n",
    "for key in bars_dict.keys():\n",
    "    export_bars(bars_dict, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export continouas bars joined together\n",
    "export_joined_bars(bars_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.3: Agrakal use-case loop workflow for every asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in tickerexchange_array:\n",
    "    run_full_process(pair[0],start,end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
