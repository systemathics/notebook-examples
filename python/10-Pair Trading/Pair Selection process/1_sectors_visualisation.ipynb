{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore the Systematics (Ganymede) API and more specifically the data that can be useful in in our pairing. These pairs will be constructed so that the assets that make them up belong to the same sector in addition to being either correlated with each other or stationary, or both. The steps will be explained as we go along in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the installations and imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations and Importations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googleapis-common-protos protobuf grpcio pandas  systemathics.apis\n",
    "!pip install statsmodels\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import grpc\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import google.protobuf as pb\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import google.type.date_pb2 as date\n",
    "import google.type.dayofweek_pb2 as dayofweek\n",
    "import google.type.timeofday_pb2 as timeofday\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, zivot_andrews\n",
    "import google.protobuf.duration_pb2 as duration\n",
    "import systemathics.apis.type.shared.v1.identifier_pb2 as identifier\n",
    "import systemathics.apis.services.daily.v1.daily_bars_pb2 as daily_bars\n",
    "import systemathics.apis.services.static_data.v1.static_data_pb2 as static_data\n",
    "import systemathics.apis.services.daily.v1.daily_bars_pb2_grpc as daily_bars_service\n",
    "import systemathics.apis.services.static_data.v1.static_data_pb2_grpc as static_data_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = f\"Bearer {os.environ['AUTH0_TOKEN']}\"\n",
    "# display(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid dispersion among all the existing assets in the world we will restrict the research within the NASDAQ index.\n",
    "\n",
    "We then define some technical parameters such as :\n",
    "* The correlation level *mincorr_level* which is used to select pairs of two assets correlated to each other at X%.\n",
    "* *use_adfuller*, *use_kpss*, *use_zivotandrews* are different methods for stationarity calculations. If the variable is assigned to *False* then the computation will not be performed.\n",
    "* *statio_level* is the invalidation threshold of the null hypothesis for the stationarity test (most of the time *p*value = 5%).\n",
    "\n",
    "As for the stationarity test, the most well-known is the Dickey-Fuller test or Dickey-Fuller unit root test. It is a statistical test that aims to find out if a time series is stationary, i.e. if its statistical properties (mathematical expectation, variance, auto-correlation) fluctuate or not over time and if their values are finite.\n",
    "\n",
    "The null hypothesis of the test is the existence of a unit root, in other words the non-stationarity of the stochastic type. This null hypothesis H0 non-stationary is invalidated if p-value < 5% and we will then consider the series as being stationary.\n",
    "\n",
    "And finally, different sector names exist within several market-based classification groups, the best known being 'ICB'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index and exchange codes\n",
    "index = 'NASDAQ'\n",
    "exchange = 'XNGS'\n",
    "\n",
    "# Set correlation and stationnarity test and level\n",
    "mincorr_level = 0.7\n",
    "use_adfuller = True\n",
    "use_kpss = False\n",
    "use_zivotandrews = False\n",
    "statio_level = 0.05\n",
    "\n",
    "# Set the market-based classification\n",
    "market_based_classification = 'Nasdaq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the token that has been allotted to us, we can make an API call by specifying at first the defined index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate static data request\n",
    "request = static_data.StaticDataRequest( \n",
    "    asset_type = static_data.AssetType.ASSET_TYPE_EQUITY\n",
    ")\n",
    "\n",
    "request.index.value = index # add index as per filter value\n",
    "# request.exchange.value = exchange # add exchange as per filter value\n",
    "request.count.value = 1000 # by default the count is set to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a gRPC channel\n",
    "with open(os.environ['SSL_CERT_FILE'], 'rb') as f:\n",
    "    credentials = grpc.ssl_channel_credentials(f.read())\n",
    "with grpc.secure_channel(os.environ['GRPC_APIS'], credentials) as channel:\n",
    "    # instantiate the static data service\n",
    "    service = static_data_service.StaticDataServiceStub(channel)\n",
    "    \n",
    "    # process the request\n",
    "    response = service.StaticData(\n",
    "        request = request, \n",
    "        metadata = [('authorization', token)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can review the response to better understand how and of what it is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(response.equities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.equities # see the response format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the line above returns a tremendous amount of rows, here is a preview :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[identifier {\n",
    "  exchange: \"XNGS\"\n",
    "  ticker: \"MELI\"\n",
    "}\n",
    "type: \"Equity\"\n",
    "country: \"US\"\n",
    "name: \"Mercadolibre Inc Common Stock\"\n",
    "currency: \"USD\"\n",
    "primary: \"XNGS\"\n",
    "tick_size_rule: \"[0:0.0001][1:0.01]\"\n",
    "mapping {\n",
    "  key: \"Bloomberg\"\n",
    "  value: \"MELI US Equity\"\n",
    "}\n",
    "mapping {\n",
    "  key: \"Esignal\"\n",
    "  value: \"MELI\"\n",
    "}\n",
    "mapping {\n",
    "  key: \"Figi\"\n",
    "  value: \"BBG000GQPB11\"\n",
    "}\n",
    "mapping {\n",
    "  key: \"Figic\"\n",
    "  value: \"BBG000GQPB11\"\n",
    "}\n",
    "mapping {\n",
    "  key: \"Idc|564\"\n",
    "  value: \"564|MELI\"\n",
    "}\n",
    "index: \"Nasdaq 100|Nasdaq Composite\"\n",
    "lot_size: 1\n",
    "point_value: 1.0\n",
    "isin: \"US58733R1023\"\n",
    "cusip: \"58733R102\"\n",
    "sedol: \"B23X1H3\"\n",
    "sectors {\n",
    "  key: \"Nasdaq\"\n",
    "  value: \"Catalog/Specialty Distribution\"\n",
    "}\n",
    "sectors {\n",
    "  key: \"SIC\"\n",
    "  value: \"7389 Services-Business Services, NEC\"\n",
    "}\n",
    "capitalization {\n",
    "  value: 59442166293.0\n",
    "}\n",
    ", identifier {\n",
    "  exchange: \"BATS\"\n",
    "  ticker: \"MELI\"\n",
    "}\n",
    "type: \"Equity\"\n",
    "country: \"US\"\n",
    "name: \"Mercadolibre Inc\"\n",
    "currency: \"USD\"\n",
    "primary: \"XNGS\"\n",
    "tick_size_rule: \"[0:0.0001][1:0.01]\"\n",
    "mapping {\n",
    "  key: \"Bloomberg\"\n",
    "  value: \"MELI UF Equity\"\n",
    "}\n",
    "mapping {\n",
    "  key: \"Esignal\"\n",
    "  value: \"MELI\"\n",
    "}\n",
    "mapping {\n",
    "  key: \"Figi\"\n",
    "  value: \"BBG000GQQVH9\"\n",
    "}\n",
    "mapping {\n",
    "  key: \"Figic\"\n",
    "  value: \"BBG000GQPB11\"\n",
    "}\n",
    "mapping {\n",
    "  key: \"Idc|729\"\n",
    "  value: \"729|MELI\"\n",
    "}\n",
    "index: \"Nasdaq 100|Nasdaq Composite\"\n",
    "open: \"09:30:00\"\n",
    "close: \"16:00:00\"\n",
    "time_zone: \"ET\"\n",
    "lot_size: 1\n",
    "point_value: 1.0\n",
    "isin: \"US58733R1023\"\n",
    "cusip: \"58733R102\"\n",
    "sedol: \"B23X1H3\"\n",
    "sectors {\n",
    "  key: \"Nasdaq\"\n",
    "  value: \"Catalog/Specialty Distribution\"\n",
    "}\n",
    "sectors {\n",
    "  key: \"SIC\"\n",
    "  value: \"7389 Services-Business Services, NEC\"\n",
    "}\n",
    ", ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of data associated with each ``identifier``. The most important ones for us are : **exchange**, **ticker**, **name** and **sector**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noticing that there are several associated sectors according to each market-based classifications such as ICB, SIC, Nasdaq, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a visualisation of all the sectors names according their market-based classification : 'ICB', 'SIC', 'GICS'...\n",
    "sectors = [equity.sectors for equity in response.equities]\n",
    "# sectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[{'SIC': '7389 Services-Business Services, NEC', 'Nasdaq': 'Catalog/Specialty Distribution'},\n",
    "\n",
    " {'SIC': '7389 Services-Business Services, NEC', 'Nasdaq': 'Catalog/Specialty Distribution'},\n",
    " \n",
    " {'SIC': '7372 Services-Prepackaged Software', 'Nasdaq': 'Computer Software: Prepackaged Software'},\n",
    " \n",
    " {'SIC': '7372 Services-Prepackaged Software', 'Nasdaq': 'Computer Software: Prepackaged Software'},\n",
    " \n",
    " {'SIC': '7372 Services-Prepackaged Software', 'Nasdaq': 'EDP Services'},\n",
    " \n",
    " {'Nasdaq': 'EDP Services', 'SIC': '7372 Services-Prepackaged Software'},\n",
    " \n",
    " {'Nasdaq': 'Broadcasting', 'SIC': '4832 Radio Broadcasting Stations'},\n",
    " \n",
    " {'SIC': '7374 Services-Computer Processing & Data Preparat', 'Nasdaq': 'Computer Software: Prepackaged Software'},\n",
    "\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display fetched equities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equities_dataframe(response):\n",
    "    \"\"\"Define a method to handle the equities reponse using a Pandas dataframe -> return the dataframe.\"\"\"\n",
    "    exchange = [equity.identifier.exchange for equity in response.equities]\n",
    "    ticker = [equity.identifier.ticker for equity in response.equities]\n",
    "    name = [equity.name for equity in response.equities]\n",
    "    primary = [equity.primary for equity in response.equities]\n",
    "    index = [equity.index for equity in response.equities]\n",
    "    isin = [equity.isin for equity in response.equities]\n",
    "    cusip = [equity.cusip for equity in response.equities]\n",
    "    sedol = [equity.sedol for equity in response.equities]\n",
    "    sector = [sectors[i][market_based_classification] for i in range(len(sectors))]   \n",
    "    \n",
    "    # Create pandas dataframe\n",
    "    d = {'Index': index, 'Name': name, 'Ticker': ticker, 'Exchange': exchange, 'Primary':primary, 'Isin': isin, 'Cusip': cusip, 'Sedol': sedol, 'Sector': sector}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a better look at the retrieved data thanks to the function written above. The selection of the sector class is done with the value that we assigned at the beginning to the *market_based_classification* variable.\n",
    "\n",
    "To avoid duplicates we will immediately filter by keeping only a specific 'Exchange'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize request results\n",
    "data = get_equities_dataframe(response)\n",
    "data = data[data.Exchange == exchange] # filter by exchange\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a readable dataframe where we have an easy visual and technical access to the name of the asset, its ticker and the sector to which it belongs in addition to other information that are not useful to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will finally begin the sorting by sectors, for that we create two lists: one regrouping them all (even duplicated) in order to verify that there are enough of them to be able to create a pair within the same sector, and a second unique list to iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the sectors in our dataframe with duplicate (needed later to count)\n",
    "all_sectors = data['Sector'].tolist()\n",
    "all_sectors = list(filter(None, all_sectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the sectors without duplicate\n",
    "unique_sectors = set(all_sectors)\n",
    "unique_sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an overview of all existing sectors according to the *market_based_classification* we have defined.\n",
    "\n",
    "The next step consists in assigning to each sector the number of assets that compose it. Indeed, we cannot create pairs within the same sector if it only contain one asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with the sectors and their total appearance\n",
    "unique_sectors = list(unique_sectors)\n",
    "tot = [all_sectors.count(sect) for sect in unique_sectors]\n",
    "cols = {'Sector': unique_sectors, 'Total': tot}\n",
    "df = pd.DataFrame(data=cols)\n",
    "ranked_total_sectors = df.sort_values(by=['Total'], ascending=False)\n",
    "ranked_total_sectors.reset_index(drop=True, inplace=True)\n",
    "ranked_total_sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command simply verifies that we retrieve the correct number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = ranked_total_sectors[ranked_total_sectors.Sector == 'EDP Services'].Total.tolist()[0]\n",
    "tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter tickers by sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is only for testing purposes, that of filtering our dataset that contains the different fields (name, tickers, sector...) by retaining only the rows of a specific sector and extracting the assets via their tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df based on a specific sector\n",
    "data_sect_filtered = data[data.Sector == 'Computer Software: Prepackaged Software']\n",
    "data_sect_filtered.reset_index(drop=True, inplace=True) # OR data_sect_filtered = data_sect_filtered.reset_index(drop=True)\n",
    "data_sect_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of tickers from a dataframe of a specific sector\n",
    "tickers_in_sector = data_sect_filtered.Ticker.tolist() # tickers_in_sector = data[data.Sector == 'Computer Software: Prepackaged Software'].Ticker.tolist()\n",
    "print(tickers_in_sector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get price and correlation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a couple of very useful functions for what comes next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``getPrice()`` function simply retrieves two lists containing the prices of an asset and the corresponding dates over the last X periods, in this case the last 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrice(exchange, ticker):\n",
    "    \"\"\"Get list of closing prices and dates of an equity from a specific exchange and ticker.\"\"\"\n",
    "    daily_request = daily_bars.DailyBarsRequest(identifier = identifier.Identifier(exchange = exchange, ticker = ticker))\n",
    "    \n",
    "    with open(os.environ['SSL_CERT_FILE'], 'rb') as f:\n",
    "        credentials = grpc.ssl_channel_credentials(f.read())\n",
    "    with grpc.secure_channel(os.environ['GRPC_APIS'], credentials) as channel:\n",
    "        daily_service = daily_bars_service.DailyBarsServiceStub(channel)\n",
    "        response = daily_service.DailyBars(request = daily_request, metadata = [('authorization', token)])\n",
    "   \n",
    "    # create lists to store close prices and dates for the pair instruments\n",
    "    length = 500 # keep last 500 points\n",
    "    dates = [datetime(ts.date.year,ts.date.month, ts.date.day ) for ts in response.data[-length:]]\n",
    "    prices = [ts.close for ts in response.data[-length:]]\n",
    "        \n",
    "    return prices, dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``logAndRatio`` returns a dataframe containing the prices of two assets, their evolution from one period to another and the ratio of the prices of these assets. In order to retrieve the prices and the dates, this function actually calls the one we defined just before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logAndRatio(exchange, ticker1, ticker2):\n",
    "    \"\"\"Return a new df with the prices of each equity via its ticker, its daily percentage change and the ratio of both.\"\"\" \n",
    "    \n",
    "    prices1, dates1 = getPrice(exchange, ticker1)\n",
    "    prices2, dates2 = getPrice(exchange, ticker2)\n",
    "    \n",
    "    data = {'Date': dates1, 'Price_1': prices1, 'Price_2': prices2}\n",
    "    df = pd.DataFrame(data=data)\n",
    "    \n",
    "    # calculate the daily percentage change and log ratio\n",
    "    df['EvolPrice_1'] = df['Price_1']/df['Price_1'].shift(1)\n",
    "    df['EvolPrice_2'] = df['Price_2']/df['Price_2'].shift(1)\n",
    "    \n",
    "    df['Ratio'] = np.log10(df['Price_1']/df['Price_2'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally ``pairCorr`` simply returns the level of correlation and stationarity between two assets. The correlation calculation is not done on the prices but on its evolution (retrieved using the previous function), you will have a better understanding of why later on with some examples. \n",
    "\n",
    "For the stationarity we just need the ratio we have calculated, then one of the three calculation methods will be executed : *adfuller*, *kpss* or *zivot-andrews* depending on whether we assigned their values to *True* or *False* at the beginning of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairCorr(exchange, ticker1, ticker2):\n",
    "    \"\"\"Return the correlation value of a pair and its stationarity.\"\"\" \n",
    "\n",
    "    df = logAndRatio(exchange, ticker1, ticker2)\n",
    "    # Because of the division in logAndRatio, some values can be so big that they are consider as infinite.\n",
    "    # Therefore we remove them so that they don't affect our correlation and stationarity computation.\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Return first the correlation of the evolution between two equities.\n",
    "    # For the stationarity return we need the pvalue that we can get at index 1,\n",
    "    # We also need to do one computation according adfuller method, kpss method or zivot-andrews's one, for that we check what variable was set to True.\n",
    "    return df['EvolPrice_1'].corr(df['EvolPrice_2']), (adfuller(df['Ratio'])[1] if use_adfuller else (kpss(df['Ratio'])[1] if use_kpss else zivot_andrews(df['Ratio'])[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick test analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some functions to display the price charts of assets constituting a pair as well as the ratio chart. Our objective is to determine if there is a certain relationship between the correlation and the stationarity of a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCharts(ticker1, ticker2, df):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.plot('Date', 'Price_1', data=df, marker='', color='orange', linewidth=1, label=\"{}\".format(ticker1))\n",
    "    plt.plot('Date', 'Price_2', data=df, marker='', color='purple', linewidth=1, label=\"{}\".format(ticker2))\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(\"{0} & {1} price over time\".format(ticker1, ticker2))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRatio(ticker1, ticker2, df):\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.plot('Date', 'Ratio', data=new_df, marker='', color='red', linewidth=1, label=\"{0}/{1} Ratio\".format(ticker1, ticker2))\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Ratio\")\n",
    "    plt.title(\"{0} & {1} ratio over time\".format(ticker1, ticker2))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCHP/AVGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker1 = 'MCHP'\n",
    "ticker2 = 'AVGO'\n",
    "\n",
    "new_df = logAndRatio('XNGS', ticker1, ticker2)\n",
    "corr, statio = pairCorr('XNGS', ticker1, ticker2)\n",
    "\n",
    "print([ticker1, ticker2, corr, statio])\n",
    "plotCharts(ticker1, ticker2, new_df)\n",
    "plotRatio(ticker1, ticker2, new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read for the MCHP/AVGO pair a correlation of 78% (at the time of the execution of this notebook the 18/12/2021) although one can observe a relatively flat curve next to another one which appears to be more volatile, this is explained by the fact that the calculation of the correlation is performed on the evolution of the price from one period to another and not on the price in itself. Indeed, an asset worth $1 at a time *t* and rising to $1.5 at *t+1* will have risen by 50% while taking only $0.50, whereas another asset worth $200 at *t* and then $300 at *t+1* will also have risen by 50% but will have increased by $100.\n",
    "\n",
    "As for the stationarity, the *p*value of 8.9% does not invalidate the null hypothesis of non-stationarity. Nevertheless, we observe on the graph a shape that seems to have some fixed variance and mean over time despite small fluctuations that do not enable us to consider the series as stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADI/TXN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker1 = 'ADI'\n",
    "ticker2 = 'TXN'\n",
    "\n",
    "new_df = logAndRatio('XNGS', ticker1, ticker2)\n",
    "corr, statio = pairCorr('XNGS', ticker1, ticker2)\n",
    "\n",
    "print([ticker1, ticker2, corr, statio])\n",
    "plotCharts(ticker1, ticker2, new_df)\n",
    "plotRatio(ticker1, ticker2, new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the ADI/TXN pair is 86% correlated and this is easily confirmed by looking at the first chart where the lines are moving within the same price range and with the same main trend direction besides the pullbacks which appear to occur mostly at the same time.\n",
    "\n",
    "Regarding stationarity, we get the same analysis as for the previous pair MCHP/AVGO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOOG/GOOGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker1 = 'GOOG'\n",
    "ticker2 = 'GOOGL'\n",
    "\n",
    "new_df = logAndRatio('XNGS', ticker1, ticker2)\n",
    "corr, statio = pairCorr('XNGS', ticker1, ticker2)\n",
    "\n",
    "print([ticker1, ticker2, corr, statio])\n",
    "plotCharts(ticker1, ticker2, new_df)\n",
    "plotRatio(ticker1, ticker2, new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, in order for Google's founders to keep control of the company they split their stocks shares in two: GOOGL shares of category A and GOOG shares of category C. The strategy behind this choice is that owners of GOOGL shares would have one vote per share, while owners of GOOG would have no voting rights. This is why GOOGL shares are generally a little more expensive than GOOG shares, although as we can see they are more than 99% correlated! We could therefore deduce that they are stationary between them but it is not so! Indeed these two stocks follow each other so much and their ratio must have a very stable variance and average over time, it only takes a small price shift for these variables to be affected and a \"stronger\" shift than usual (but in appearance not very violent) to completely disrupt the variance and mean over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGEN/MRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker1 = 'SGEN'\n",
    "ticker2 = 'MRNA'\n",
    "\n",
    "new_df = logAndRatio('XNGS', ticker1, ticker2)\n",
    "corr, statio = pairCorr('XNGS', ticker1, ticker2)\n",
    "\n",
    "print([ticker1, ticker2, corr, statio])\n",
    "plotCharts(ticker1, ticker2, new_df)\n",
    "plotRatio(ticker1, ticker2, new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this last example SGEN and MRNA are not correlated at all (only 12.5%) and it is very obvious that they are not stationary either: a declining trend implying a variance that is not stable at all and a mean that will continue to fall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this very quick study of testing a few combinations of assets within the same sector, we can assume that a correlated pair is not necessarily stationary although it may seem to be close, however, we have not conducted enough tests to make a general statement. Likewise, an uncorrelated pair does not seem to be stationary but is it true all the time ? Can't we find stationary but uncorrelated pairs ?\n",
    "\n",
    "To find out possible answers to these questions we will investigate further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next step we will go through all the sectors and retrieve the assets composing them in order to compare them two by two and give them a correlation and stationarity coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(unique_sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_and_statio_list = []\n",
    "\n",
    "for sect in unique_sectors:\n",
    "    if ranked_total_sectors[ranked_total_sectors.Sector == sect].Total.tolist()[0] >= 2: # check if the sector contain at least two equity\n",
    "        tickers_in_sector = data[data.Sector == sect].Ticker.tolist() # get all the tickers that belongs to that sector\n",
    "        print(sect)\n",
    "        print(tickers_in_sector)\n",
    "        for ticker1, ticker2 in itertools.combinations(tickers_in_sector, 2): # compare all data in list in twos\n",
    "            corr, statio = pairCorr('XNGS', ticker1, ticker2)\n",
    "            corr_and_statio_list.append([ticker1, ticker2, corr, statio])\n",
    "    \n",
    "print()\n",
    "\n",
    "corr_and_statio_list.sort(key=lambda x: abs(x[3])) # sort according the stationnarity (at index 3)\n",
    "df_correlation = pd.DataFrame(corr_and_statio_list, columns=['Ticker 1', 'Ticker 2', 'Correlation', 'Stationnarity'])\n",
    "df_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will display on a graph the resulting values in order to get a better understanding of them :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = np.polyfit(df_correlation['Correlation'], df_correlation['Stationnarity'], 1)\n",
    "predict = np.poly1d(model)\n",
    "df_correlation['Linear Regression'] = predict(df_correlation['Correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.scatter(df_correlation['Correlation'], df_correlation['Stationnarity'], color=\"black\", label=\"Stationnarity per correlation\")\n",
    "plt.plot(df_correlation['Correlation'], df_correlation['Linear Regression'], color=\"purple\", label=\"Linear Regression\")\n",
    "plt.axvspan(mincorr_level, 1, color='red', alpha=0.3)\n",
    "plt.axhspan(0, statio_level, color='blue', alpha=0.3)\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.ylabel(\"Stationnarity\")\n",
    "plt.title(\"Stationnarity per correlation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is once again quite interesting, indeed, we do not distinguish a clear trend between the correlation (on the x-axis) and stationarity (y-axis) and although the linear regression seems to indicate a very slight relationship it is not yet sufficient to make a claim. *Moreover, when applying another method of stationarity calculation such as kpss or zivot-andrews the result is not so different.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning the distribution of the points, we notice that among the pairs that we considered as being sufficiently correlated at X% to be selected (red zone), none of them invalidate the null hypothesis of non-stationarity (blue zone for a *p*value < 5%). We can even observe that there are a fair number of pairs that are highly correlated but far from being stationary and conversely stationary but absolutely not correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topcorrelation = df_correlation[df_correlation.Correlation > mincorr_level][df_correlation.Stationnarity < statio_level].reset_index(drop=True) if (use_adfuller or use_zivotandrews) else df_correlation[df_correlation.Correlation > mincorr_level][df_correlation.Stationnarity > statio_level].reset_index(drop=True)\n",
    "df_topcorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not getting any result that meets our variables set at the beginning, we will adjust the correlation to 50% just to complete the simulation and save the supposedly valid selected data in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topcorrelation = df_correlation[df_correlation.Correlation > 0.5][df_correlation.Stationnarity < statio_level].reset_index(drop=True) if (use_adfuller or use_zivotandrews) else df_correlation[df_correlation.Correlation > mincorr_level][df_correlation.Stationnarity > statio_level].reset_index(drop=True)\n",
    "df_topcorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topcorrelation.to_json('records.json', orient = 'records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the format of the resulting json :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "[\n",
    "    {\"Ticker 1\":\"CPRT\",\"Ticker 2\":\"CTAS\",\"Correlation\":0.6684001207,\"Stationnarity\":0.010620222,\"Linear Regression\":0.5239802538},\n",
    "    {\"Ticker 1\":\"CPRT\",\"Ticker 2\":\"PAYX\",\"Correlation\":0.6663459713,\"Stationnarity\":0.0151790611,\"Linear Regression\":0.523461077},\n",
    "    {\"Ticker 1\":\"WDAY\",\"Ticker 2\":\"ANSS\",\"Correlation\":0.6102550992,\"Stationnarity\":0.0180939327,\"Linear Regression\":0.5092843655},\n",
    "    {\"Ticker 1\":\"XLNX\",\"Ticker 2\":\"AMD\",\"Correlation\":0.6987437769,\"Stationnarity\":0.0243699886,\"Linear Regression\":0.5316494742},\n",
    "    {\"Ticker 1\":\"MRVL\",\"Ticker 2\":\"AMD\",\"Correlation\":0.5727479704,\"Stationnarity\":0.0310797982,\"Linear Regression\":0.4998046102},\n",
    "    {\"Ticker 1\":\"WDAY\",\"Ticker 2\":\"ADSK\",\"Correlation\":0.6258423816,\"Stationnarity\":0.0341574382,\"Linear Regression\":0.5132239799},\n",
    "    {\"Ticker 1\":\"SNPS\",\"Ticker 2\":\"CDW\",\"Correlation\":0.5917000704,\"Stationnarity\":0.0365893486,\"Linear Regression\":0.5045946668}\n",
    "]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
