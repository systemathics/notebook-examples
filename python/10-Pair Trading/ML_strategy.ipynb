{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Requirement pip install</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.9/site-packages (1.53.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.9/site-packages (3.19.0)\n",
      "Requirement already satisfied: grpcio in /opt/conda/lib/python3.9/site-packages (1.41.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: systemathics.apis in /opt/conda/lib/python3.9/site-packages (0.9.71)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.9/site-packages (from grpcio) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (21.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install googleapis-common-protos protobuf grpcio pandas matplotlib systemathics.apis\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import grpc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import google.type.date_pb2 as date\n",
    "import google.type.dayofweek_pb2 as dayofweek\n",
    "import google.type.timeofday_pb2 as timeofday\n",
    "import google.protobuf.duration_pb2 as duration\n",
    "import systemathics.apis.type.shared.v1.identifier_pb2 as identifier\n",
    "import systemathics.apis.services.daily.v1.daily_bars_pb2 as daily_bars\n",
    "import systemathics.apis.services.daily.v1.daily_bars_pb2_grpc as daily_bars_service\n",
    "from math import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Authentification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImpwZDhjS2Z5Zi13QXkzOURpNENqWSJ9.eyJpc3MiOiJodHRwczovL2dhbnltZWRlLXByb2QuZXUuYXV0aDAuY29tLyIsInN1YiI6ImF1dGgwfDYxNTE4OTRmNWQzZDlkMDA3MGUzNjM0ZSIsImF1ZCI6WyJodHRwczovL3Byb2QuZ2FueW1lZGUtcHJvZCIsImh0dHBzOi8vZ2FueW1lZGUtcHJvZC5ldS5hdXRoMC5jb20vdXNlcmluZm8iXSwiaWF0IjoxNjQyMzc0NTgwLCJleHAiOjE2NDQ5NjY1ODAsImF6cCI6Ijl5R0tzbGtFczFWNm9xRk9aa0h0a1V0NWkyNTVackpJIiwic2NvcGUiOiJvcGVuaWQgcHJvZmlsZSBlbWFpbCIsInBlcm1pc3Npb25zIjpbInNlcnZpY2VzOmJhc2ljIl19.pRK-BHLXJ8cZGkWJL-NdP5rigJnwWpjIp8kt3GxdkvMp49jOvjiuIBKrprXWJD_NBFeTk88YQUJGAg2T48fU90FcaO2igbYu5OF9S_lrlJ0ZEoQvnKrvioWCkyetnNmC1dKM-KsFqeZ0Sox8da6AivkF_i5GBfvOvMoF2BcXKP9uEqeWyPdZpn_OaTzZ6VoMTvvN90RtEnrzRhY13DTt1RMn-mYoeDlhZzcuaI0UcozjcucwvvzF1MqersViGn3o6xrf3_J6FUB_efSYoImoMXP1YQw9iYxyvMsTY1Ry9IQ3l4UkCFWFYRXH9-Y6QdP7OgC-bR81hgZ_f_h0KynwCQ'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token = f\"Bearer {os.environ['AUTH0_TOKEN']}\"\n",
    "display(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Get Data of pairs selected for the dataset</h1>\n",
    "\n",
    "<p> The indicators we calculate which are going to be used by the model to predict future spread are the following ones : the normalized spread, the correlation between the two assets on the last 30 days, the volatility on the last 30 days, the volume in the last period, the spread evolution with the last period, the spread moving average in the last 7 days, the week and the month (seasonality could have an impact).<space><space> \n",
    "\n",
    "This might be enough though, we could add at least correlation and volatility on different windows or others indicators (why not an indicator measuring the current fear on the market?)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bars for ticker1 retrieved:  3137\n",
      "Total bars for ticker2 retrieved:  5297\n"
     ]
    }
   ],
   "source": [
    "# set the instruments identifiers: tickers and exchange\n",
    "exchange = \"XNGS\"\n",
    "\n",
    "# Below we have all the pairs used to constitute the dataset\n",
    "ticker_1 =\"ADSK\"\n",
    "ticker_2 =\"CHKP\"\n",
    "\"\"\"\n",
    "ticker_1 =\"EA\"\n",
    "ticker_2 =\"SPLK\"\n",
    "\n",
    "ticker_1 =\"AVGO\"\n",
    "ticker_2 =\"ADI\"\n",
    "\n",
    "ticker_1 =\"CPRT\"\n",
    "ticker_2 =\"PAYX\"\n",
    "\n",
    "ticker_1 =\"TXN\"\n",
    "ticker_2 =\"NXPI\"\n",
    "\n",
    "ticker_1 =\"BIIB\"\n",
    "ticker_2 =\"GILD\"\n",
    "\n",
    "ticker_1 =\"MU\"\n",
    "ticker_2 =\"INTC\"\n",
    "\n",
    "ticker_1 =\"ADP\"\n",
    "ticker_2 =\"CTAS\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# create daily bars requests for the pair instruments\n",
    "daily_request_1 = daily_bars.DailyBarsRequest(identifier = identifier.Identifier(exchange = exchange, ticker = ticker_1))\n",
    "daily_request_2 = daily_bars.DailyBarsRequest(identifier = identifier.Identifier(exchange = exchange, ticker = ticker_2))\n",
    "\n",
    "# open a gRPC channel, instantiate the daily bars service and get the reply for the 1st instrument\n",
    "with open(os.environ['SSL_CERT_FILE'], 'rb') as f:\n",
    "    credentials = grpc.ssl_channel_credentials(f.read())\n",
    "with grpc.secure_channel(os.environ['GRPC_APIS'], credentials) as channel:\n",
    "    daily_service = daily_bars_service.DailyBarsServiceStub(channel)\n",
    "    response_1 = daily_service.DailyBars(request = daily_request_1, metadata = [('authorization', token)])\n",
    "    \n",
    "print(\"Total bars for ticker1 retrieved: \",len(response_1.data))\n",
    "\n",
    "# open a gRPC channel, instantiate the daily bars service and get the reply for the 2nd instrument\n",
    "with open(os.environ['SSL_CERT_FILE'], 'rb') as f:\n",
    "    credentials = grpc.ssl_channel_credentials(f.read())\n",
    "with grpc.secure_channel(os.environ['GRPC_APIS'], credentials) as channel:\n",
    "    daily_service = daily_bars_service.DailyBarsServiceStub(channel)\n",
    "    response_2 = daily_service.DailyBars(request = daily_request_2, metadata = [('authorization', token)])\n",
    "    \n",
    "print(\"Total bars for ticker2 retrieved: \",len(response_2.data))\n",
    "\n",
    "# create pandas dataframe to store close prices for the pair instruments\n",
    "length = 1000 # keep last 500 points\n",
    "dates = [datetime(ts.date.year,ts.date.month, ts.date.day ) for ts in response_2.data[-length:]]\n",
    "prices1 = [ts.close for ts in response_1.data[-length:]]\n",
    "prices2 = [ts.close for ts in response_2.data[-length:]]\n",
    "data = {'Date': dates, 'Price_1': prices1, 'Price_2': prices2}\n",
    "df = pd.DataFrame(data=data)\n",
    "df['Price_1'] = pd.to_numeric(df['Price_1'])\n",
    "df['Price_2'] = pd.to_numeric(df['Price_2'])\n",
    "\n",
    "\n",
    "# Here we calculate all the indicators used as variables by the Machine Learning models to predict later \n",
    "\n",
    "df['Rol1'] = df['Price_1'].shift(periods=5)   # Here we get the price 5 periods before to get the evolution on one week\n",
    "df['Rol2'] = df['Price_2'].shift(periods=5)\n",
    "\n",
    "df['Spread'] = np.log10(df['Price_1'] / df['Rol1']) - np.log10(df['Price_2'] / df['Rol2'])    #  cf Formula used to calculate the spread\n",
    "df['z_score']=(df['Spread']-df['Spread'].rolling(window=30).mean())/df['Spread'].rolling(window=30).std()  # Here we calculate the spread normalized \n",
    "\n",
    "df['z_score_evol']=df['z_score']-df['z_score'].shift(periods=1)   # We get the evolution of the spread on one period\n",
    "\n",
    "df['z_score_avg_week']=df['z_score'].rolling(window=5).mean() # We calculate the average spread on the week\n",
    "\n",
    "period=30 # Period used for the historical volatility\n",
    "\n",
    "number_days=252   #Number of trading days in a year (to get annualized volatility)\n",
    "\n",
    "df['log_returns1'] = np.log(df['Price_1']/df['Price_1'].shift(periods=1))\n",
    "df['log_returns2'] = np.log(df['Price_2']/df['Price_2'].shift(periods=1))\n",
    "\n",
    "df['volatility1']= df['log_returns1'].rolling(window=period).std()*np.sqrt(number_days)  # Volatility of the first asset\n",
    "df['volatility2']= df['log_returns2'].rolling(window=period).std()*np.sqrt(number_days)  # Volatility of the second asset\n",
    "\n",
    "df['avg_volatility']=(df['volatility1']+df['volatility2'])/2  # We calculate the average volatility of the two assets\n",
    "\n",
    "df['correlation']=0\n",
    "\n",
    "for i in range (len(df)):\n",
    "    df['correlation'].iloc[i]=df['Price_1'].iloc[i-30:i].corr(df['Price_2'].iloc[i-30:i])  # Correlation between the two assets in the last 30 periods\n",
    "df['corr_evol']=df['correlation']-df['correlation'].shift(periods=1)\n",
    "\n",
    "#df[['year','month','day']]= df.Date.str.split(\"-\",expand=True)\n",
    "df['month'] = df['Date'].dt.month  # Current month \n",
    "df['week'] = df['Date'].dt.isocalendar().week  # Current week of the year\n",
    "\n",
    "df=df.drop(columns=['volatility1', 'volatility2','log_returns1','log_returns2','Rol1','Rol2'])  # We drop columns only used to calculate the indicators we wanted\n",
    "\n",
    "df['future_z_score']= df['z_score'].shift(-5)  # We get the future normalized spread in 5 periods, which is going to be our target for the ML models\n",
    "\n",
    "def target (spread):\n",
    "    if spread>1.5:\n",
    "        return 1\n",
    "    elif spread<-1.5 :\n",
    "        return -1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "df['target']= df['future_z_score'].apply(target)\n",
    "df=df.drop(columns=['future_z_score'])   # We drop the future normalized spread since we are making it a classification problem with the target function\n",
    "df=df[::5]   # We keep only one row out of 5 periods since we dont want the model to be able to use data between the day it makes the prediction and the day the prediction \n",
    "# is verified, otherwise it would be cheating\n",
    "df\n",
    "df.to_csv(r'./data1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating the dataset </h1>\n",
    "\n",
    "<p> We built a dataset from 8 different pairs that are stationary over the recovered period. We then grouped all the data into one dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('./data1.csv')\n",
    "df2=pd.read_csv('./data2.csv')\n",
    "df3=pd.read_csv('./data3.csv')\n",
    "df4=pd.read_csv('./data4.csv')\n",
    "df5=pd.read_csv('./data5.csv')\n",
    "df6=pd.read_csv('./data6.csv')\n",
    "df7=pd.read_csv('./data7.csv')\n",
    "df8=pd.read_csv('./data8.csv')\n",
    "\n",
    "frames=[df1,df2,df3,df4,df5,df6,df7,df8]\n",
    "dataset=pd.concat(frames)\n",
    "dataset.to_csv('./dataset.csv')  # Saving the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    1365\n",
       " 1     126\n",
       "-1     109\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target'].value_counts()  # We see that 90% of the time the normalised spread is between -1.5 and 1.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loading the dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('./dataset.csv') \n",
    "dataset=dataset.drop(columns=\"Unnamed: 0\")\n",
    "dataset=dataset.sample(frac=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training/Test Sets</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=dataset[int(0.8*len(df)):]  # Using 80% as a training set and 20% for the test\n",
    "df_train=dataset[:int(0.8*len(df))]\n",
    "\n",
    "df_test = df_test.dropna()\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "\n",
    "df_test = df_test.dropna().sample(frac=1).reset_index(drop=True)\n",
    "df_train = df_train.dropna().sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Below we create the variables part X and the target part y\n",
    "\n",
    "y_train=df_train[['target']]\n",
    "y_test=df_test[['target']]\n",
    "\n",
    "X_train=df_train.drop(columns=['target'])\n",
    "X_test=df_test.drop(columns=['target'])\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating/evaluating the ML models </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()  #Using a random forest classifier\n",
    "rf = rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "print(\"accuracy_score: %.2f\"% accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier() #Using a gradient boosting classifier\n",
    "gb = gb.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "print(y_pred,len(y_pred))\n",
    "\n",
    "print(\"accuracy_score: %.2f\"% accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(max_iter=1000)   #Using a logistic regression\n",
    "reg = reg.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "print(y_pred)\n",
    "    \n",
    "print(\"accuracy_score: %.2f\"% accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using the Machine Learning model in a backtest </h1>\n",
    "\n",
    "<p> In this part we try the ML strategy on only one pair. Strategy used for the backtest: an entry in position takes place when the model predicts a normalized spread that will be higher than 1.5 in a week or lower than -1.5. If the model predicts a normalized spread higher than 1.5, a long position is taken (long asset 1 and short asset 2) because this means that asset 1 should perform better than asset 2 according to the algorithm (in the opposite case a short position is taken). We keep the position as long as the model predicts future spread higher than 1.5 or lower thant -1.5 for a short.\n",
    "\n",
    "The issue here is that the number of trades will be meaningless. The next step would be to test this strategy with the pair selection we did for the complete backtest.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the instruments identifiers: tickers and exchange\n",
    "exchange = \"XNGS\"\n",
    "\n",
    "# Below we have all the pairs used to constitute the dataset\n",
    "ticker_1 =\"AAPL\"\n",
    "ticker_2 =\"MSFT\"\n",
    "\n",
    "\n",
    "# create daily bars requests for the pair instruments\n",
    "daily_request_1 = daily_bars.DailyBarsRequest(identifier = identifier.Identifier(exchange = exchange, ticker = ticker_1))\n",
    "daily_request_2 = daily_bars.DailyBarsRequest(identifier = identifier.Identifier(exchange = exchange, ticker = ticker_2))\n",
    "\n",
    "# open a gRPC channel, instantiate the daily bars service and get the reply for the 1st instrument\n",
    "with open(os.environ['SSL_CERT_FILE'], 'rb') as f:\n",
    "    credentials = grpc.ssl_channel_credentials(f.read())\n",
    "with grpc.secure_channel(os.environ['GRPC_APIS'], credentials) as channel:\n",
    "    daily_service = daily_bars_service.DailyBarsServiceStub(channel)\n",
    "    response_1 = daily_service.DailyBars(request = daily_request_1, metadata = [('authorization', token)])\n",
    "    \n",
    "print(\"Total bars for ticker1 retrieved: \",len(response_1.data))\n",
    "\n",
    "# open a gRPC channel, instantiate the daily bars service and get the reply for the 2nd instrument\n",
    "with open(os.environ['SSL_CERT_FILE'], 'rb') as f:\n",
    "    credentials = grpc.ssl_channel_credentials(f.read())\n",
    "with grpc.secure_channel(os.environ['GRPC_APIS'], credentials) as channel:\n",
    "    daily_service = daily_bars_service.DailyBarsServiceStub(channel)\n",
    "    response_2 = daily_service.DailyBars(request = daily_request_2, metadata = [('authorization', token)])\n",
    "    \n",
    "print(\"Total bars for ticker2 retrieved: \",len(response_2.data))\n",
    "\n",
    "# create pandas dataframe to store close prices for the pair instruments\n",
    "length = 1000 # keep last 500 points\n",
    "dates = [datetime(ts.date.year,ts.date.month, ts.date.day ) for ts in response_2.data[-length:]]\n",
    "prices1 = [ts.close for ts in response_1.data[-length:]]\n",
    "prices2 = [ts.close for ts in response_2.data[-length:]]\n",
    "data = {'Date': dates, 'Price_1': prices1, 'Price_2': prices2}\n",
    "df = pd.DataFrame(data=data)\n",
    "df['Price_1'] = pd.to_numeric(df['Price_1'])\n",
    "df['Price_2'] = pd.to_numeric(df['Price_2'])\n",
    "\n",
    "\n",
    "# Here we calculate all the indicators used as variables by the Machine Learning models to predict later \n",
    "\n",
    "df['Rol1'] = df['Price_1'].shift(periods=5)   # Here we get the price 5 periods before to get the evolution on one week\n",
    "df['Rol2'] = df['Price_2'].shift(periods=5)\n",
    "\n",
    "df['Spread'] = np.log10(df['Price_1'] / df['Rol1']) - np.log10(df['Price_2'] / df['Rol2'])    #  cf Formula used to calculate the spread\n",
    "df['z_score']=(df['Spread']-df['Spread'].rolling(window=30).mean())/df['Spread'].rolling(window=30).std()  # Here we calculate the spread normalized \n",
    "\n",
    "df['z_score_evol']=df['z_score']-df['z_score'].shift(periods=1)   # We get the evolution of the spread on one period\n",
    "\n",
    "df['z_score_avg_week']=df['z_score'].rolling(window=5).mean() # We calculate the average spread on the week\n",
    "\n",
    "period=30 # Period used for the historical volatility\n",
    "\n",
    "number_days=252   #Number of trading days in a year (to get annualized volatility)\n",
    "\n",
    "df['log_returns1'] = np.log(df['Price_1']/df['Price_1'].shift(periods=1))\n",
    "df['log_returns2'] = np.log(df['Price_2']/df['Price_2'].shift(periods=1))\n",
    "\n",
    "df['volatility1']= df['log_returns1'].rolling(window=period).std()*np.sqrt(number_days)  # Volatility of the first asset\n",
    "df['volatility2']= df['log_returns2'].rolling(window=period).std()*np.sqrt(number_days)  # Volatility of the second asset\n",
    "\n",
    "df['avg_volatility']=(df['volatility1']+df['volatility2'])/2  # We calculate the average volatility of the two assets\n",
    "\n",
    "df['correlation']=0\n",
    "\n",
    "for i in range (len(df)):\n",
    "    df['correlation'].iloc[i]=df['Price_1'].iloc[i-30:i].corr(df['Price_2'].iloc[i-30:i])  # Correlation between the two assets in the last 30 periods\n",
    "df['corr_evol']=df['correlation']-df['correlation'].shift(periods=1)\n",
    "\n",
    "#df[['year','month','day']]= df.Date.str.split(\"-\",expand=True)\n",
    "df['month'] = df['Date'].dt.month  # Current month \n",
    "df['week'] = df['Date'].dt.isocalendar().week  # Current week of the year\n",
    "\n",
    "df=df.drop(columns=['volatility1', 'volatility2','log_returns1','log_returns2','Rol1','Rol2'])  # We drop columns only used to calculate the indicators we wanted\n",
    "\n",
    "df['future_z_score']= df['z_score'].shift(-5)  # We get the future normalized spread in 5 periods, which is going to be our target for the ML models\n",
    "\n",
    "def target (spread):\n",
    "    if spread>1.5:\n",
    "        return 1\n",
    "    elif spread<-1.5 :\n",
    "        return -1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "df['target']= df['future_z_score'].apply(target)\n",
    "df=df.drop(columns=['future_z_score'])   # We drop the future normalized spread since we are making it a classification problem with the target function\n",
    "df=df[::5]   # We keep only one row out of 5 periods since we dont want the model to be able to use data between the day it makes the prediction and the day the prediction \n",
    "# is verified, otherwise it would be cheating\n",
    "df\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict=df.drop(columns=['Date','target'])\n",
    "y_pred = gb.predict(to_predict)\n",
    "y_pred\n",
    "#Here we predict the future normalised spread used to define our postions entries/exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df\n",
    "df=df.drop(columns=['Date'])\n",
    "df['predicted']=y_pred\n",
    "df['Date']=temp['Date']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeBacktest(dt):\n",
    "    dt['multiplier'] = 1 + dt['tradeResult']\n",
    "    dt['cumulativeResult'] = dt['multiplier'].cumprod()\n",
    "\n",
    "    dt['tradeIs'] = ''\n",
    "    dt.loc[dt['tradeResult']>0,'tradeIs'] = 'Good'\n",
    "    dt.loc[dt['tradeResult']<=0,'tradeIs'] = 'Bad'\n",
    "    dt['tradeResult'] = dt['tradeResult'] * 100  \n",
    "\n",
    "    dt['tradeResult'] = pd.to_numeric(dt['tradeResult'])\n",
    "\n",
    "    dt['highValue'] = dt['cumulativeResult'].cummax()\n",
    "\n",
    "    dt['drawdown'] = dt['cumulativeResult'] - dt['highValue']\n",
    "    dt['drawdown'] = pd.to_numeric(dt['drawdown'])\n",
    "\n",
    "    # print(pd.isnull(dt.iloc[-1]['cumulativeResult']))\n",
    "    # print(pd.isnull(dt.iloc[-2]['cumulativeResult']))\n",
    "    strategyFinalResult = (dt.iloc[-2]['cumulativeResult']-1) if pd.isnull(dt.iloc[-1]['cumulativeResult']) else (dt.iloc[-1]['cumulativeResult']-1)\n",
    "    # print(strategyFinalResult)\n",
    "\n",
    "    try:\n",
    "        tradesPerformance = round(dt.loc[(dt['tradeIs'] == 'Good') | (dt['tradeIs'] == 'Bad'), 'tradeResult'].sum()\n",
    "                / dt.loc[(dt['tradeIs'] == 'Good') | (dt['tradeIs'] == 'Bad'), 'tradeResult'].count(), 2)\n",
    "    except:\n",
    "        tradesPerformance = 0\n",
    "        print(\"/!\\ There is no Good or Bad Trades in your BackTest, maybe a problem...\")\n",
    "\n",
    "    try:\n",
    "        totalGoodTrades = dt.groupby('tradeIs')['date'].nunique()['Good']\n",
    "        AveragePercentagePositivTrades = round(dt.loc[dt['tradeIs'] == 'Good', 'tradeResult'].sum()\n",
    "                                               / dt.loc[dt['tradeIs'] == 'Good', 'tradeResult'].count(), 2)\n",
    "        idbest = dt.loc[dt['tradeIs'] == 'Good', 'tradeResult'].idxmax()\n",
    "        bestTrade = str(\n",
    "            round(dt.loc[dt['tradeIs'] == 'Good', 'tradeResult'].max(), 2))\n",
    "    except:\n",
    "        totalGoodTrades = 0\n",
    "        AveragePercentagePositivTrades = 0\n",
    "        idbest = ''\n",
    "        bestTrade = 0\n",
    "        print(\"/!\\ There is no Good Trades in your BackTest, maybe a problem...\")\n",
    "\n",
    "    try:\n",
    "        totalBadTrades = dt.groupby('tradeIs')['date'].nunique()['Bad']\n",
    "        AveragePercentageNegativTrades = round(dt.loc[dt['tradeIs'] == 'Bad', 'tradeResult'].sum()\n",
    "                                               / dt.loc[dt['tradeIs'] == 'Bad', 'tradeResult'].count(), 2)\n",
    "        idworst = dt.loc[dt['tradeIs'] == 'Bad', 'tradeResult'].idxmin()\n",
    "        worstTrade = round(dt.loc[dt['tradeIs'] == 'Bad', 'tradeResult'].min(), 2)\n",
    "    except:\n",
    "        totalBadTrades = 0\n",
    "        AveragePercentageNegativTrades = 0\n",
    "        idworst = ''\n",
    "        worstTrade = 0\n",
    "        print(\"/!\\ There is no Bad Trades in your BackTest, maybe a problem...\")\n",
    "\n",
    "    totalTrades = totalBadTrades + totalGoodTrades\n",
    "\n",
    "    try:\n",
    "        TotalLongTrades = len(dt.loc[(dt['position'] == 'LONG') & (dt['openOrClose'] == 'Close')])\n",
    "        AverageLongTrades = round((dt.loc[(dt['position'] == 'LONG') & (dt['openOrClose'] == 'Close'), 'tradeResult'].sum() / TotalLongTrades),2)\n",
    "        idBestLong = dt.loc[dt['position'] == 'LONG', 'tradeResult'].idxmax()\n",
    "        bestLongTrade = str(\n",
    "            round(dt.loc[dt['position'] == 'LONG', 'tradeResult'].max(), 2))\n",
    "        idWorstLong = dt.loc[dt['position'] == 'LONG', 'tradeResult'].idxmin()\n",
    "        worstLongTrade = str(\n",
    "            round(dt.loc[dt['position'] == 'LONG', 'tradeResult'].min(), 2))\n",
    "    except:\n",
    "        AverageLongTrades = 0\n",
    "        TotalLongTrades = 0\n",
    "        bestLongTrade = ''\n",
    "        idBestLong = ''\n",
    "        idWorstLong = ''\n",
    "        worstLongTrade = ''\n",
    "        print(\"/!\\ There is no LONG Trades in your BackTest, maybe a problem...\")\n",
    "\n",
    "    try:\n",
    "        TotalShortTrades = len(dt.loc[(dt['position'] == 'SHORT') & (dt['openOrClose'] == 'Close')])\n",
    "        AverageShortTrades = round(dt.loc[dt['position'] == 'SHORT', 'tradeResult'].sum()\n",
    "                                   / dt.loc[dt['position'] == 'SHORT', 'tradeResult'].count(), 2)\n",
    "        idBestShort = dt.loc[dt['position'] == 'SHORT', 'tradeResult'].idxmax()\n",
    "        bestShortTrade = str(\n",
    "            round(dt.loc[dt['position'] == 'SHORT', 'tradeResult'].max(), 2))\n",
    "        idWorstShort = dt.loc[dt['position'] == 'SHORT', 'tradeResult'].idxmin()\n",
    "        worstShortTrade = str(\n",
    "            round(dt.loc[dt['position'] == 'SHORT', 'tradeResult'].min(), 2))\n",
    "    except:\n",
    "        AverageShortTrades = 0\n",
    "        TotalShortTrades = 0\n",
    "        bestShortTrade = ''\n",
    "        idBestShort = ''\n",
    "        idWorstShort = ''\n",
    "        worstShortTrade = ''\n",
    "        print(\"/!\\ There is no SHORT Trades in your BackTest, maybe a problem...\")\n",
    "\n",
    "    try:\n",
    "        totalGoodLongTrade = dt.groupby(['position', 'tradeIs']).size()['LONG']['Good']\n",
    "    except:\n",
    "        totalGoodLongTrade = 0\n",
    "        print(\"/!\\ There is no good LONG Trades in your BackTest, maybe a problem...\")\n",
    "\n",
    "    try:\n",
    "        totalBadLongTrade = dt.groupby(['position', 'tradeIs']).size()['LONG']['Bad']\n",
    "    except:\n",
    "        totalBadLongTrade = 0\n",
    "        print(\"/!\\ There is no bad LONG Trades in your BackTest, maybe a problem...\")\n",
    "\n",
    "    try:\n",
    "        totalGoodShortTrade = dt.groupby(['position', 'tradeIs']).size()['SHORT']['Good']\n",
    "    except:\n",
    "        totalGoodShortTrade = 0\n",
    "        print(\"/!\\ There is no good SHORT Trades in your BackTest, maybe a problem...\")\n",
    "\n",
    "    try:\n",
    "        totalBadShortTrade = dt.groupby(['position', 'tradeIs']).size()['SHORT']['Bad']\n",
    "    except:\n",
    "        totalBadShortTrade = 0\n",
    "        print(\"/!\\ There is no bad SHORT Trades in your BackTest, maybe a problem...\")\n",
    "        \n",
    "    try:\n",
    "        dt['timeDeltaTrade'] = dt[\"timeSince\"]\n",
    "        dt['timeDeltaNoTrade'] = dt['timeDeltaTrade']\n",
    "        dt.loc[dt['openOrClose'] ==\n",
    "                     'Open', 'timeDeltaTrade'] = None\n",
    "        dt.loc[dt['openOrClose'] ==\n",
    "                     'Close', 'timeDeltaNoTrade'] = None\n",
    "    except:\n",
    "        print(\"/!\\ Error in time delta\")\n",
    "        dt['timeDeltaTrade'] = 0\n",
    "        dt['timeDeltaNoTrade'] = 0\n",
    "\n",
    "    winRateRatio = (totalGoodTrades/totalTrades) * 100\n",
    "\n",
    "    maxDrawdown = dt['drawdown'].min()\n",
    "    maxDrawdownId = dt['drawdown'].idxmin()\n",
    "    \n",
    "    print(\"Pair Strategy on : \" + ticker_1 + \"/\" + ticker_2)\n",
    "    print(\"Period : [\" + str(df.iloc[0]['Date']) + \"] -> [\" +\n",
    "          str(str(df.iloc[-1]['Date']) + \"]\"))\n",
    "\n",
    "    print(\"\\n----- General Informations -----\")\n",
    "    print(\"Performance vs US Dollar :\", round(strategyFinalResult*100, 2), \"%\")\n",
    "    print(\"Best trade : +\"+bestTrade, \"%, the\", dt.iloc[idbest]['date'])\n",
    "    print(\"Worst trade :\", worstTrade, \"%, the\", dt.iloc[idworst]['date'])\n",
    "    print(\"Max DrawDown :\", str(round(100*maxDrawdown, 2)), \"%, the\", dt.iloc[maxDrawdownId]['date'])\n",
    "\n",
    "    print(\"\\n----- Trades Informations -----\")\n",
    "    print(\"Total trades on period :\",totalTrades)\n",
    "    print(\"Number of positive trades :\", totalGoodTrades)\n",
    "    print(\"Number of negative trades : \", totalBadTrades)\n",
    "    print(\"Trades win rate ratio :\", round(winRateRatio, 2), '%')\n",
    "    print(\"Average trades performance :\",tradesPerformance,\"%\")\n",
    "    print(\"Average positive trades :\", AveragePercentagePositivTrades, \"%\")\n",
    "    print(\"Average negative trades :\", AveragePercentageNegativTrades, \"%\")\n",
    "\n",
    "    print(\"\\n----- LONG Trades Informations -----\")\n",
    "    print(\"Number of LONG trades :\",TotalLongTrades)\n",
    "    print(\"Average LONG trades performance :\",AverageLongTrades, \"%\")\n",
    "    print(\"Best  LONG trade +\"+bestLongTrade, \"%, the \", dt.iloc[idBestLong]['date'])\n",
    "    print(\"Worst LONG trade\", worstLongTrade, \"%, the \", dt.iloc[idWorstLong]['date'])\n",
    "    print(\"Number of positive LONG trades :\",totalGoodLongTrade)\n",
    "    print(\"Number of negative LONG trades :\",totalBadLongTrade)\n",
    "    print(\"LONG trade win rate ratio :\", round(totalGoodLongTrade/TotalLongTrades*100, 2), '%')\n",
    "\n",
    "    print(\"\\n----- SHORT Trades Informations -----\")\n",
    "    print(\"Number of SHORT trades :\",TotalShortTrades)\n",
    "    print(\"Average SHORT trades performance :\",AverageShortTrades, \"%\")\n",
    "    print(\"Best  SHORT trade +\"+bestShortTrade, \"%, the \", dt.iloc[idBestShort]['date'])\n",
    "    print(\"Worst SHORT trade\", worstShortTrade, \"%, the \", dt.iloc[idWorstShort]['date'])\n",
    "    print(\"Number of positive SHORT trades :\",totalGoodShortTrade)\n",
    "    print(\"Number of negative SHORT trades :\",totalBadShortTrade)\n",
    "    print(\"SHORT trade win rate ratio :\", round(totalGoodShortTrade/TotalShortTrades*100, 2), '%')\n",
    "    \n",
    "    print(\"\\n----- Time Informations -----\")\n",
    "    print(\"Average time duration for a trade :\", round(\n",
    "        dt['timeDeltaTrade'].mean(skipna=True), 2), \"periods\")\n",
    "    print(\"Maximum time duration for a trade :\",\n",
    "          dt['timeDeltaTrade'].max(skipna=True), \"periods\")\n",
    "    print(\"Minimum time duration for a trade :\",\n",
    "          dt['timeDeltaTrade'].min(skipna=True), \"periods\")\n",
    "    print(\"Average time duration between two trades :\", round(\n",
    "        dt['timeDeltaNoTrade'].mean(skipna=True), 2), \"periods\")\n",
    "    print(\"Maximum time duration between two trades :\",\n",
    "          dt['timeDeltaNoTrade'].max(skipna=True), \"periods\")\n",
    "    print(\"Minimum time duration between two trades :\",\n",
    "          dt['timeDeltaNoTrade'].min(skipna=True), \"periods\")\n",
    "    \n",
    "    print(\"\\n----- Trades Reasons -----\")\n",
    "    reasons = dt['reason'].unique()\n",
    "    for r in reasons:\n",
    "        print(r+\" number :\", dt.groupby('reason')\n",
    "              ['date'].nunique()[r])\n",
    "        \n",
    "def plot_wallet_evolution(dfTrades):\n",
    "    dfTrades = dfTrades.set_index(dfTrades['date'])\n",
    "    dfTrades.index = pd.to_datetime(dfTrades.index)\n",
    "    dfTrades['wallet'].plot(figsize=(20, 10))\n",
    "    print(\"\\n----- Plot -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = None\n",
    "dt = pd.DataFrame(columns=['date', 'openOrClose', 'position', 'price1', 'price2', 'tradeResult', 'wallet'])\n",
    "dfTest = df.copy()\n",
    "#dfTest.drop(columns=\"target\")\n",
    "# df['Date'] = pd.to_datetime(df['Date'])  \n",
    "# mask = (df['Date'] >= '2020-02') & (df['Date'] <= '2020-06')\n",
    "# dfTest = df.loc[mask]\n",
    "initialWallet = 1000\n",
    "wallet = initialWallet\n",
    "orderInProgress = ''\n",
    "previousRow = dfTest.iloc[0]\n",
    "lastPrice1 = 0\n",
    "lastPrice2 = 0\n",
    "currentTimeOpen = 0\n",
    "timeSince = 0\n",
    "\n",
    "# -- Hyper parameters --\n",
    "stopLossActivation = True\n",
    "timeLimitActivation = True\n",
    "spreadBuy = 0.017\n",
    "speadSell = -0.017\n",
    "slPct = 0.05\n",
    "timeLimit = 10\n",
    "\n",
    "\n",
    "# -- Backtest functions --\n",
    "def openLongCondition(row, previousRow):\n",
    "    if(row['predicted'] == 1 and previousRow['predicted'] < 1):\n",
    "#     if(row['Spread'] < speadSell):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def closeLongCondition(row, previousRow):\n",
    "    if(row['predicted'] > -2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def openShortCondition(row, previousRow):\n",
    "    if(row['predicted'] == -1 and previousRow['predicted'] > -1):\n",
    "#     if(row['Spread'] > spreadBuy):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def closeShortCondition(row, previousRow):\n",
    "    if(row['Spread'] < 4):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# -- Utility fonction --\n",
    "def getTradeResult(position, price1, price2, lastPrice1, lastPrice2):\n",
    "    evolPrice1 = (price1 - lastPrice1) / lastPrice1\n",
    "    evolPrice2 = (price2 - lastPrice2) / lastPrice2\n",
    "    if position == 'LONG':\n",
    "        return evolPrice1-evolPrice2\n",
    "    else:\n",
    "        return evolPrice2-evolPrice1\n",
    "\n",
    "# -- Backtesting --\n",
    "for index, row in dfTest.iterrows():\n",
    "    timeSince += 1\n",
    "    if currentTimeOpen > 0:\n",
    "        currentTimeOpen += 1\n",
    "        # -- If there is an order in progress --\n",
    "    if orderInProgress != '':\n",
    "        # -- Check if there is a LONG order in progress --\n",
    "        if orderInProgress == 'LONG':\n",
    "            tradeResult = getTradeResult(\"LONG\", row['Price_1'], row['Price_2'], lastPrice1, lastPrice2)\n",
    "            if tradeResult < -slPct and stopLossActivation:\n",
    "                orderInProgress = ''\n",
    "                wallet = wallet + tradeResult * wallet\n",
    "                # -- Add the trade to DT to analyse it later --\n",
    "                closeLongRow = {\n",
    "                    'date': row['Date'], \n",
    "                    'openOrClose':'Close', \n",
    "                    'position': \"LONG\", \n",
    "                    'price1': row['Price_1'], \n",
    "                    'price2': row['Price_2'],\n",
    "                    'tradeResult': tradeResult,\n",
    "                    'wallet': wallet,\n",
    "                    'reason': 'Close Long Stop Loss',\n",
    "                    'timeSince': timeSince\n",
    "                }\n",
    "                dt = dt.append(closeLongRow, ignore_index=True)\n",
    "                timeSince = 0\n",
    "                \n",
    "            elif currentTimeOpen > timeLimit:\n",
    "                orderInProgress = ''\n",
    "                wallet = wallet + tradeResult * wallet\n",
    "                # -- Add the trade to DT to analyse it later --\n",
    "                closeLongRow = {\n",
    "                    'date': row['Date'], \n",
    "                    'openOrClose':'Close', \n",
    "                    'position': \"LONG\", \n",
    "                    'price1': row['Price_1'], \n",
    "                    'price2': row['Price_2'],\n",
    "                    'tradeResult': tradeResult,\n",
    "                    'wallet': wallet,\n",
    "                    'reason': 'Close Long Time Limit',\n",
    "                    'timeSince': timeSince\n",
    "                }\n",
    "                dt = dt.append(closeLongRow, ignore_index=True)\n",
    "                timeSince = 0\n",
    "            # -- Check If you have to close the LONG --\n",
    "            elif closeLongCondition(row, previousRow) == True:\n",
    "                orderInProgress = ''\n",
    "                wallet = wallet + tradeResult * wallet\n",
    "                # -- Add the trade to DT to analyse it later --\n",
    "                closeLongRow = {\n",
    "                    'date': row['Date'], \n",
    "                    'openOrClose':'Close', \n",
    "                    'position': \"LONG\", \n",
    "                    'price1': row['Price_1'], \n",
    "                    'price2': row['Price_2'],\n",
    "                    'tradeResult': tradeResult,\n",
    "                    'wallet': wallet,\n",
    "                    'reason': 'Close Long Market',\n",
    "                    'timeSince': timeSince\n",
    "                }\n",
    "                dt = dt.append(closeLongRow, ignore_index=True)\n",
    "                timeSince = 0\n",
    "        if orderInProgress == 'SHORT':\n",
    "            tradeResult = getTradeResult(\"SHORT\", row['Price_1'], row['Price_2'], lastPrice1, lastPrice2)\n",
    "            if tradeResult < -slPct and stopLossActivation:\n",
    "                orderInProgress = ''\n",
    "                wallet = wallet + tradeResult * wallet\n",
    "                # -- Add the trade to DT to analyse it later --\n",
    "                closeShortRow = {\n",
    "                    'date': row['Date'], \n",
    "                    'openOrClose':'Close', \n",
    "                    'position': \"SHORT\", \n",
    "                    'price1': row['Price_1'], \n",
    "                    'price2': row['Price_2'],\n",
    "                    'tradeResult': tradeResult,\n",
    "                    'wallet': wallet,\n",
    "                    'reason': 'Close Short Stop Loss',\n",
    "                    'timeSince': timeSince\n",
    "                }\n",
    "                dt = dt.append(closeShortRow, ignore_index=True)\n",
    "                timeSince = 0\n",
    "                \n",
    "            elif currentTimeOpen > timeLimit:\n",
    "                orderInProgress = ''\n",
    "                wallet = wallet + tradeResult * wallet\n",
    "                # -- Add the trade to DT to analyse it later --\n",
    "                closeShortRow = {\n",
    "                    'date': row['Date'], \n",
    "                    'openOrClose':'Close', \n",
    "                    'position': \"SHORT\", \n",
    "                    'price1': row['Price_1'], \n",
    "                    'price2': row['Price_2'],\n",
    "                    'tradeResult': tradeResult,\n",
    "                    'wallet': wallet,\n",
    "                    'reason': 'Close Short Time Limit',\n",
    "                    'timeSince': timeSince\n",
    "                }\n",
    "                dt = dt.append(closeShortRow, ignore_index=True)\n",
    "                timeSince = 0\n",
    "            # -- Check If you have to close the LONG --\n",
    "            elif closeShortCondition(row, previousRow) == True:\n",
    "                orderInProgress = ''\n",
    "                wallet = wallet + tradeResult * wallet\n",
    "                # -- Add the trade to DT to analyse it later --\n",
    "                closeShortRow = {\n",
    "                    'date': row['Date'], \n",
    "                    'openOrClose':'Close', \n",
    "                    'position': \"SHORT\", \n",
    "                    'price1': row['Price_1'], \n",
    "                    'price2': row['Price_2'],\n",
    "                    'tradeResult': tradeResult,\n",
    "                    'wallet': wallet,\n",
    "                    'reason': 'Close Short Market',\n",
    "                    'timeSince': timeSince\n",
    "                }\n",
    "                dt = dt.append(closeShortRow, ignore_index=True)\n",
    "                timeSince = 0\n",
    "                \n",
    "    # -- If there is NO order in progress --\n",
    "    elif orderInProgress == '':\n",
    "        if openLongCondition(row, previousRow) == True:\n",
    "            orderInProgress = 'LONG'\n",
    "            lastPrice1 = row['Price_1']\n",
    "            lastPrice2 = row['Price_2']\n",
    "            if timeLimitActivation:\n",
    "                currentTimeOpen = 1\n",
    "            openLongRow = {\n",
    "                'date': row['Date'], \n",
    "                'openOrClose':'Open', \n",
    "                'position': \"LONG\", \n",
    "                'price1': row['Price_1'], \n",
    "                'price2': row['Price_2'],\n",
    "                'wallet': wallet,\n",
    "                'reason': 'Open Long Market',\n",
    "                'timeSince': timeSince\n",
    "            }\n",
    "            dt = dt.append(openLongRow, ignore_index=True)\n",
    "            timeSince = 0\n",
    "            \n",
    "        if openShortCondition(row, previousRow) == True:\n",
    "            orderInProgress = 'SHORT'\n",
    "            lastPrice1 = row['Price_1']\n",
    "            lastPrice2 = row['Price_2']\n",
    "            if timeLimitActivation:\n",
    "                currentTimeOpen = 1            \n",
    "            closeShortRow = {\n",
    "                'date': row['Date'], \n",
    "                'openOrClose':'Open', \n",
    "                'position': \"SHORT\", \n",
    "                'price1': row['Price_1'], \n",
    "                'price2': row['Price_2'],\n",
    "                'wallet': wallet,\n",
    "                'reason': 'Open Short Market',\n",
    "                'timeSince': timeSince\n",
    "            }\n",
    "            dt = dt.append(closeShortRow, ignore_index=True)\n",
    "            timeSince = 0\n",
    "    previousRow = row        \n",
    "\n",
    "    \n",
    "# print('Final wallet',round(wallet,2),'$')\n",
    "nbGoodTrade = dt['date'].loc[dt['tradeResult']>0].count()\n",
    "nbTotalTrade = dt['date'].loc[dt['openOrClose'] == 'Close'].count()\n",
    "winRateRatio = nbGoodTrade / nbTotalTrade\n",
    "# print('Win rate ratio :', round(winRateRatio*100,2), '%')\n",
    "completeBacktest(dt)\n",
    "plot_wallet_evolution(dt)\n",
    "# dt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
